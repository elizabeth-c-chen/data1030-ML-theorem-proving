{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import  Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, ParameterGrid, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import f1_score,  precision_score, recall_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from skmultilearn.problem_transform import LabelPowerset, ClassifierChain\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/features_plus_descriptions.csv')\n",
    "features.set_index('Feature Type and Number', inplace=True)\n",
    "features.drop(['S5', 'D21'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H0_Best</th>\n",
       "      <th>H1_Best</th>\n",
       "      <th>H2_Best</th>\n",
       "      <th>H3_Best</th>\n",
       "      <th>H4_Best</th>\n",
       "      <th>H5_Best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    H0_Best  H1_Best  H2_Best  H3_Best  H4_Best  H5_Best\n",
       "0         1        0        0        0        0        0\n",
       "1         0        1        1        0        1        1\n",
       "2         1        0        0        0        0        0\n",
       "3         1        0        0        0        0        0\n",
       "4         1        0        0        0        0        0\n",
       "5         1        0        0        0        0        0\n",
       "6         1        0        0        0        0        0\n",
       "7         1        0        0        0        0        0\n",
       "8         1        0        0        0        0        0\n",
       "9         1        0        0        0        0        0\n",
       "10        1        0        0        0        0        0\n",
       "11        0        1        1        0        1        1\n",
       "12        0        1        1        0        1        1\n",
       "13        0        0        0        1        0        0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = ['H0_Best','H1_Best', 'H2_Best', 'H3_Best', 'H4_Best', 'H5_Best']\n",
    "\n",
    "df = pd.read_csv('../data/multiclass_LP_transformed_raw_data.csv')\n",
    "X = df.loc[:, features.index]\n",
    "y = df[target]\n",
    "y[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "print(len(features.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax Scaler Features:  ['S1', 'S3', 'S4', 'S6', 'S8', 'S11', 'S12', 'D3', 'D39']\n",
      "Standard Scaler Features:  ['S2', 'S7', 'S9', 'S10', 'S13', 'S14', 'D1', 'D2', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'D16', 'D17', 'D18', 'D19', 'D20', 'D22', 'D23', 'D24', 'D25', 'D26', 'D27', 'D28', 'D29', 'D30', 'D31', 'D32', 'D33', 'D34', 'D35', 'D36', 'D37', 'D38']\n"
     ]
    }
   ],
   "source": [
    "types = dict.fromkeys(features.index, 'stdsc')\n",
    "mm_feats = ['S1','S3', 'S4', 'S6', 'S8','S11', 'S12', 'D3', 'D39']\n",
    "\n",
    "for feat in mm_feats:\n",
    "    types[feat] = 'minmax'\n",
    "\n",
    "minmax_feats = []\n",
    "std_feats = []\n",
    "\n",
    "for feat in types.keys():\n",
    "    if types[feat] == 'stdsc':\n",
    "        std_feats.append(feat)\n",
    "    elif types[feat] == 'minmax':\n",
    "        minmax_feats.append(feat)\n",
    "\n",
    "print('MinMax Scaler Features: ', minmax_feats)\n",
    "print('Standard Scaler Features: ', std_feats)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('mm_scaler', MinMaxScaler(), minmax_feats),\n",
    "        ('std_scaler', StandardScaler(), std_feats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline_KFold_LP(X, y, preprocessor, param_grid, label_powerset, verbose=5):\n",
    "    prec_scores = []\n",
    "    rec_scores = []\n",
    "    f1_scores = []\n",
    "    best_models = []\n",
    "    ys = []\n",
    "    for i in range(10):\n",
    "        random_state = 431 * i\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "        clf = Pipeline([\n",
    "        ('preprocessor', preprocessor), \n",
    "        ('clf', label_powerset)\n",
    "        ])\n",
    "        grid = GridSearchCV(clf,  param_grid, scoring='f1_macro', cv=kf, return_train_score=True, verbose=verbose, n_jobs=-1)   \n",
    "        grid.fit(X_other, y_other)\n",
    "        y_pred = grid.predict(X_test)\n",
    "        prec = precision_score(y_test, y_pred, average=\"macro\")\n",
    "        rec = recall_score(y_test, y_pred, average=\"macro\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        print(\"best estimator\", grid.best_params_, \"precision score\", prec, \"recall score\", rec, \"f1 score\", f1)\n",
    "        best_models.append(grid.best_params_)\n",
    "        prec_scores.append(prec)\n",
    "        rec_scores.append(rec)\n",
    "        f1_scores.append(f1)\n",
    "        ys.append((label_powerset.transform(y_test), label_powerset.transform(y_pred), label_powerset.reverse_combinations_, label_powerset.unique_combinations_))\n",
    "    test_scores = [prec_scores, rec_scores, f1_scores]\n",
    "    return test_scores, best_models, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:    1.0s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:    1.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': DummyClassifier(strategy='uniform'), 'clf__strategy': 'uniform'} precision score 0.2634201955086679 recall score 0.49893043988196356 f1 score 0.3367361922725059\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': DummyClassifier(strategy='uniform'), 'clf__strategy': 'uniform'} precision score 0.26177685044361554 recall score 0.48332614061494916 f1 score 0.33551420992135533\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': DummyClassifier(strategy='uniform'), 'clf__strategy': 'uniform'} precision score 0.263790476953163 recall score 0.5077632403482509 f1 score 0.3407032411181768\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': DummyClassifier(strategy='uniform'), 'clf__strategy': 'uniform'} precision score 0.26253635581871826 recall score 0.5043401816683535 f1 score 0.3391278692412711\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': DummyClassifier(strategy='uniform'), 'clf__strategy': 'uniform'} precision score 0.27312442978548446 recall score 0.5103229441750087 f1 score 0.34921553993023363\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': DummyClassifier(strategy='uniform'), 'clf__strategy': 'uniform'} precision score 0.2630864840211404 recall score 0.5016672737071005 f1 score 0.33921749423797093\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': DummyClassifier(strategy='uniform'), 'clf__strategy': 'uniform'} precision score 0.2656011339109125 recall score 0.5024977580324437 f1 score 0.340550796871949\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': DummyClassifier(strategy='uniform'), 'clf__strategy': 'uniform'} precision score 0.2742457769109228 recall score 0.49752505673954667 f1 score 0.3476578747872765\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': DummyClassifier(strategy='uniform'), 'clf__strategy': 'uniform'} precision score 0.2732857142691926 recall score 0.5009334266880511 f1 score 0.34840574233649724\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': DummyClassifier(strategy='uniform'), 'clf__strategy': 'uniform'} precision score 0.2589097964804005 recall score 0.4964716562364111 f1 score 0.33485364382470917\n"
     ]
    }
   ],
   "source": [
    "param_grid = {  'clf': [DummyClassifier()],\n",
    "                'clf__strategy': [\"stratified\", \"most_frequent\", \"prior\", \"uniform\", \"constant\"]}\n",
    "\n",
    "scores_LP_dummy, models_LP_dummy, xx = ML_pipeline_KFold_LP(X, y, preprocessor, param_grid, LabelPowerset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   50.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': RandomForestClassifier(max_depth=25, max_features=51), 'clf__max_depth': 25, 'clf__max_features': 51} precision score 0.7409578923490715 recall score 0.5992742421523504 f1 score 0.6606785525717488\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': RandomForestClassifier(max_depth=35, max_features=35), 'clf__max_depth': 35, 'clf__max_features': 35} precision score 0.7704478527629613 recall score 0.5924918681042989 f1 score 0.6675486089300251\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': RandomForestClassifier(max_depth=40, max_features=40), 'clf__max_depth': 40, 'clf__max_features': 40} precision score 0.746864875577428 recall score 0.5891012458623174 f1 score 0.6573480007320912\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   54.6s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': RandomForestClassifier(max_depth=25, max_features=35), 'clf__max_depth': 25, 'clf__max_features': 35} precision score 0.7289148630401011 recall score 0.5783718761756497 f1 score 0.6437175885996266\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   52.6s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': RandomForestClassifier(max_depth=25, max_features=15), 'clf__max_depth': 25, 'clf__max_features': 15} precision score 0.7491813797290602 recall score 0.599244597215084 f1 score 0.6647912179598328\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   52.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': RandomForestClassifier(max_depth=35, max_features=51), 'clf__max_depth': 35, 'clf__max_features': 51} precision score 0.7436739883511115 recall score 0.5936681605417241 f1 score 0.6593691503763403\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   53.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': RandomForestClassifier(max_depth=25, max_features=25), 'clf__max_depth': 25, 'clf__max_features': 25} precision score 0.7598547810260672 recall score 0.6012978540299326 f1 score 0.6692242246144025\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   51.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': RandomForestClassifier(max_depth=20, max_features=35), 'clf__max_depth': 20, 'clf__max_features': 35} precision score 0.7491240822179236 recall score 0.5859880302927093 f1 score 0.6557835010138127\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': RandomForestClassifier(max_depth=25, max_features=20), 'clf__max_depth': 25, 'clf__max_features': 20} precision score 0.7568708039253399 recall score 0.6000475710265033 f1 score 0.6683760190392501\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   50.9s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': RandomForestClassifier(max_depth=20, max_features=45), 'clf__max_depth': 20, 'clf__max_features': 45} precision score 0.7502400716118086 recall score 0.5836876337780571 f1 score 0.654117559539748\n"
     ]
    }
   ],
   "source": [
    "param_grid = {  'clf': [RandomForestClassifier()],\n",
    "                'clf__max_depth': [15, 20, 25, 30, 35, 40], # 5, 7, \n",
    "                'clf__max_features': [15, 20, 25, 30, 35, 40, 45, 51]} # 4, 8, \n",
    "\n",
    "scores_LP_RF, models_LP_RF, ys = ML_pipeline_KFold_LP(X, y, preprocessor, param_grid, LabelPowerset(), verbose=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  64 | elapsed:   10.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   10.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': KNeighborsClassifier(weights='distance'), 'clf__n_neighbors': 5, 'clf__weights': 'distance'} precision score 0.6837683718396629 recall score 0.5990183309870312 f1 score 0.6377527823277211\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  64 | elapsed:   10.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   10.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': KNeighborsClassifier(weights='distance'), 'clf__n_neighbors': 5, 'clf__weights': 'distance'} precision score 0.7108053998963872 recall score 0.5991383499554908 f1 score 0.6481764410973766\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  64 | elapsed:   10.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': KNeighborsClassifier(weights='distance'), 'clf__n_neighbors': 5, 'clf__weights': 'distance'} precision score 0.6879775811570709 recall score 0.6209547407025001 f1 score 0.6518742731520786\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  64 | elapsed:   10.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': KNeighborsClassifier(weights='distance'), 'clf__n_neighbors': 5, 'clf__weights': 'distance'} precision score 0.6723382492601756 recall score 0.5958014439547328 f1 score 0.6314950157675446\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  64 | elapsed:   10.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': KNeighborsClassifier(weights='distance'), 'clf__n_neighbors': 5, 'clf__weights': 'distance'} precision score 0.7018835838934923 recall score 0.6102520607841965 f1 score 0.6519558233215222\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  64 | elapsed:   10.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': KNeighborsClassifier(weights='distance'), 'clf__n_neighbors': 5, 'clf__weights': 'distance'} precision score 0.6789116779025265 recall score 0.6046637711767389 f1 score 0.6383819031181458\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  64 | elapsed:   10.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': KNeighborsClassifier(weights='distance'), 'clf__n_neighbors': 5, 'clf__weights': 'distance'} precision score 0.7071932015263092 recall score 0.6196120156425385 f1 score 0.6592409065257201\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  64 | elapsed:   10.7s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   10.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': KNeighborsClassifier(weights='distance'), 'clf__n_neighbors': 5, 'clf__weights': 'distance'} precision score 0.6892854967703195 recall score 0.592806025127644 f1 score 0.6364880718533638\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  64 | elapsed:   10.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': KNeighborsClassifier(weights='distance'), 'clf__n_neighbors': 5, 'clf__weights': 'distance'} precision score 0.6912060542906682 recall score 0.6221273737124694 f1 score 0.6539230573867166\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  64 | elapsed:   10.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   10.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator {'clf': KNeighborsClassifier(weights='distance'), 'clf__n_neighbors': 5, 'clf__weights': 'distance'} precision score 0.6758868561110928 recall score 0.5890445095448369 f1 score 0.6282457774557305\n"
     ]
    }
   ],
   "source": [
    "param_grid ={ 'clf': [KNeighborsClassifier()], \n",
    "              'clf__n_neighbors': [5,10,15,20,30,40,50,60],\n",
    "              'clf__weights': ['distance', 'uniform'] }\n",
    "\n",
    "scores_LP_KNN, models_LP_KNN, ys_LP_KNN = ML_pipeline_KFold_LP(X, y, preprocessor, param_grid, LabelPowerset(), verbose=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random state: 431 * 0\n",
      "working on params:   {'solver': 'newton-cg', 'penalty': 'l2', 'C': 1.0}\n",
      "mean train f1 score: 0.3722376197766682 mean validation f1 score: 0.33712264519633056\n",
      "working on params:   {'solver': 'newton-cg', 'penalty': 'l2', 'C': 10.0}\n",
      "mean train f1 score: 0.4006042069559428 mean validation f1 score: 0.3599816193346029\n",
      "working on params:   {'solver': 'newton-cg', 'penalty': 'l2', 'C': 100.0}\n",
      "mean train f1 score: 0.4175288492320535 mean validation f1 score: 0.37131775727072924\n",
      "working on params:   {'solver': 'newton-cg', 'penalty': 'l2', 'C': 1000.0}\n",
      "mean train f1 score: 0.4285598031052149 mean validation f1 score: 0.37421435098172995\n",
      "working on params:   {'solver': 'newton-cg', 'penalty': 'l2', 'C': 10000.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-186acdbac4ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mX_val_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mX_test_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/skmultilearn/problem_transform/lp.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         self.classifier.fit(self._ensure_input_format(X),\n\u001b[0;32m--> 141\u001b[0;31m                             self.transform(y))\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1415\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1417\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = { 'penalty': ['l2'],\n",
    "               'C': np.logspace(0, 4, 5),\n",
    "               'solver': ['newton-cg'] }\n",
    "param_grid = ParameterGrid(param_grid)\n",
    "test_scores = np.zeros(10)\n",
    "final_models = []\n",
    "\n",
    "for i in range(10):\n",
    "    random_state = 431 * i \n",
    "    print('random state: 431 * {}'.format(i))\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "            \n",
    "    models = []\n",
    "    train_scores = np.zeros(shape=(4, len(param_grid)))\n",
    "    val_scores = np.zeros(shape=(4, len(param_grid)))\n",
    "    \n",
    "    for p in range(len(param_grid)):\n",
    "        params = param_grid[p]\n",
    "        print('working on params:  ', params) \n",
    "        clf = LabelPowerset(LogisticRegression(**params,random_state=random_state, max_iter=10000, \n",
    "                                            warm_start=True, multi_class='multinomial',  n_jobs=-1))\n",
    "        j = 0\n",
    "        for train_index, val_index in kf.split(X_other):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            X_train_prep = preprocessor.fit_transform(X_train)\n",
    "            X_val_prep = preprocessor.transform(X_val)\n",
    "            X_test_prep = preprocessor.transform(X_test)\n",
    "            clf.fit(X_train_prep, y_train)\n",
    "            \n",
    "            y_train_pred = clf.predict(X_train_prep)\n",
    "            prec = precision_score(y_train, y_train_pred, average=\"macro\", zero_division=0)\n",
    "            rec = recall_score(y_train, y_train_pred, average=\"macro\")\n",
    "            f1 = f1_score(y_train, y_train_pred, average=\"macro\")\n",
    "         #   print('train:', i, \"precision score\", prec, \"recall score\", rec, \"f1 score\", f1)\n",
    "            train_scores[j][p] = f1\n",
    "            \n",
    "            y_val_pred = clf.predict(X_val_prep)\n",
    "            prec_val = precision_score(y_val, y_val_pred, average=\"macro\", zero_division=0)\n",
    "            rec_val = recall_score(y_val, y_val_pred, average=\"macro\")\n",
    "            f1_val = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "          #  print('validation:', i, \"precision score\", prec_val, \"recall score\", rec_val, \"f1 score\", f1_val)\n",
    "            val_scores[j][p] = f1_val\n",
    "            j += 1\n",
    "        models.append(clf) \n",
    "            \n",
    "        print('mean train f1 score:', np.mean(train_scores[:, p]), '    mean validation f1 score:', np.mean(val_scores[:, p]))\n",
    "    amax_mean = np.argmax(np.mean(val_scores, axis=0))\n",
    "    print('The best model parameters were:', param_grid[amax_mean])\n",
    "    print('The corresponding mean validation score is:',np.max(np.mean(val_scores, axis=0)))\n",
    "    final_models.append(models[amax_mean])\n",
    "    y_test_pred = final_models[-1].predict(X_test_prep)\n",
    "    test_scores[i] = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "    print('Test Score: ', test_scores[i])\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "L = LabelPowerset()\n",
    "\n",
    "y_svc = L.transform(y)\n",
    "\n",
    "scores_LP_SVC, models_LP_SVC, ys_LP_SVC = ML_pipeline_KFold_LP(X, y_svc, preprocessor, param_grid, LabelPowerset(), verbose=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random state: 431 * 0\n",
      "working on params:   {'tol': 1e-05, 'C': 10.0}\n",
      "mean train f1 score: 0.5803715570447965 mean validation f1 score: 0.4535622916690111\n",
      "working on params:   {'tol': 0.0001, 'C': 10.0}\n",
      "mean train f1 score: 0.5803715570447965 mean validation f1 score: 0.4535622916690111\n",
      "working on params:   {'tol': 0.001, 'C': 10.0}\n",
      "mean train f1 score: 0.5803715570447965 mean validation f1 score: 0.4535622916690111\n",
      "working on params:   {'tol': 0.01, 'C': 10.0}\n",
      "mean train f1 score: 0.580227548030398 mean validation f1 score: 0.4534683804972424\n",
      "working on params:   {'tol': 1e-05, 'C': 39.810717055349734}\n",
      "mean train f1 score: 0.6807236753677993 mean validation f1 score: 0.5053965695399787\n",
      "working on params:   {'tol': 0.0001, 'C': 39.810717055349734}\n",
      "mean train f1 score: 0.6807236753677993 mean validation f1 score: 0.5053965695399787\n",
      "working on params:   {'tol': 0.001, 'C': 39.810717055349734}\n",
      "mean train f1 score: 0.6807236753677993 mean validation f1 score: 0.5053788536119304\n",
      "working on params:   {'tol': 0.01, 'C': 39.810717055349734}\n",
      "mean train f1 score: 0.6807645864018788 mean validation f1 score: 0.505493101519659\n",
      "working on params:   {'tol': 1e-05, 'C': 158.48931924611142}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c8539d406c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mtrain_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0my_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_prep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mprec_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mrec_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/skmultilearn/problem_transform/lp.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# this will be an np.array of integers representing classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mlp_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_input_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_probB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             cache_size=self.cache_size)\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = { 'C': np.logspace(1,4,num=4),\n",
    "               'tol': np.logspace(-5, -2,num=4) }\n",
    "\n",
    "param_grid = ParameterGrid(param_grid)\n",
    "test_scores = np.zeros(10)\n",
    "final_models = []\n",
    "\n",
    "for i in range(10):\n",
    "    random_state = 431 * i \n",
    "    print('random state: 431 * {}'.format(i))\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "            \n",
    "    models = []\n",
    "    train_scores = np.zeros(shape=(4, len(param_grid)))\n",
    "    val_scores = np.zeros(shape=(4, len(param_grid)))\n",
    "    \n",
    "    for p in range(len(param_grid)):\n",
    "        params = param_grid[p]\n",
    "        print('working on params:  ', params) \n",
    "        clf = LabelPowerset(SVC(**params,random_state=random_state, max_iter=100000, cache_size=1000))\n",
    "        j = 0\n",
    "        for train_index, val_index in kf.split(X_other):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            X_train_prep = preprocessor.fit_transform(X_train)\n",
    "            X_val_prep = preprocessor.transform(X_val)\n",
    "            X_test_prep = preprocessor.transform(X_test)\n",
    "            clf.fit(X_train_prep, y_train)\n",
    "            \n",
    "            y_train_pred = clf.predict(X_train_prep)\n",
    "            prec = precision_score(y_train, y_train_pred, average=\"macro\", zero_division=0)\n",
    "            rec = recall_score(y_train, y_train_pred, average=\"macro\")\n",
    "            f1 = f1_score(y_train, y_train_pred, average=\"macro\")\n",
    "         #   print('train:', i, \"precision score\", prec, \"recall score\", rec, \"f1 score\", f1)\n",
    "            train_scores[j][p] = f1\n",
    "            \n",
    "            y_val_pred = clf.predict(X_val_prep)\n",
    "            prec_val = precision_score(y_val, y_val_pred, average=\"macro\", zero_division=0)\n",
    "            rec_val = recall_score(y_val, y_val_pred, average=\"macro\")\n",
    "            f1_val = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "          #  print('validation:', i, \"precision score\", prec_val, \"recall score\", rec_val, \"f1 score\", f1_val)\n",
    "            val_scores[j][p] = f1_val\n",
    "            j += 1\n",
    "        models.append(clf) \n",
    "            \n",
    "        print('mean train f1 score:', np.mean(train_scores[:, p]), '    mean validation f1 score:', np.mean(val_scores[:, p]))\n",
    "    amax_mean = np.argmax(np.mean(val_scores, axis=0))\n",
    "    print('The best model parameters were:', param_grid[amax_mean])\n",
    "    print('The corresponding mean validation score is:',np.max(np.mean(val_scores, axis=0)))\n",
    "    final_models.append(models[amax_mean])\n",
    "    y_test_pred = final_models[-1].predict(X_test_prep)\n",
    "    test_scores[i] = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "    print('Test Score: ', test_scores[i])\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random state: 431 * 0\n",
      "working on params:   {'tol': 1e-05, 'C': 100000.0}\n",
      "mean train f1 score: 0.9455544801372688 mean validation f1 score: 0.572010051170791\n",
      "working on params:   {'tol': 0.0001, 'C': 100000.0}\n",
      "mean train f1 score: 0.9455544801372688 mean validation f1 score: 0.572010051170791\n",
      "working on params:   {'tol': 0.001, 'C': 100000.0}\n",
      "mean train f1 score: 0.9455544801372688 mean validation f1 score: 0.572010051170791\n",
      "working on params:   {'tol': 0.01, 'C': 100000.0}\n",
      "mean train f1 score: 0.9455167881131996 mean validation f1 score: 0.5721401719842774\n",
      "working on params:   {'tol': 1e-05, 'C': 1000000.0}\n",
      "mean train f1 score: 0.9659223760396642 mean validation f1 score: 0.5700681635023653\n",
      "working on params:   {'tol': 0.0001, 'C': 1000000.0}\n",
      "mean train f1 score: 0.9659223760396642 mean validation f1 score: 0.5700681635023653\n",
      "working on params:   {'tol': 0.001, 'C': 1000000.0}\n",
      "mean train f1 score: 0.9659223760396642 mean validation f1 score: 0.5703308081079496\n",
      "working on params:   {'tol': 0.01, 'C': 1000000.0}\n",
      "mean train f1 score: 0.9659223760396642 mean validation f1 score: 0.5700868597184878\n",
      "working on params:   {'tol': 1e-05, 'C': 10000000.0}\n",
      "mean train f1 score: 0.9719047162748176 mean validation f1 score: 0.5644253585541447\n",
      "working on params:   {'tol': 0.0001, 'C': 10000000.0}\n",
      "mean train f1 score: 0.9719047162748176 mean validation f1 score: 0.5644253585541447\n",
      "working on params:   {'tol': 0.001, 'C': 10000000.0}\n",
      "mean train f1 score: 0.9719047162748176 mean validation f1 score: 0.5645599519102065\n",
      "working on params:   {'tol': 0.01, 'C': 10000000.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-709faf6b1e67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mX_val_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mX_test_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/skmultilearn/problem_transform/lp.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         self.classifier.fit(self._ensure_input_format(X),\n\u001b[0;32m--> 141\u001b[0;31m                             self.transform(y))\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = { 'C': np.logspace(5,7,num=3),\n",
    "               'tol': np.logspace(-5, -2,num=4) }\n",
    "\n",
    "param_grid = ParameterGrid(param_grid)\n",
    "test_scores = np.zeros(10)\n",
    "final_models = []\n",
    "\n",
    "for i in range(10):\n",
    "    random_state = 431 * i \n",
    "    print('random state: 431 * {}'.format(i))\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "            \n",
    "    models = []\n",
    "    train_scores = np.zeros(shape=(4, len(param_grid)))\n",
    "    val_scores = np.zeros(shape=(4, len(param_grid)))\n",
    "    \n",
    "    for p in range(len(param_grid)):\n",
    "        params = param_grid[p]\n",
    "        print('working on params:  ', params) \n",
    "        clf = LabelPowerset(SVC(**params,random_state=random_state, max_iter=10000000, cache_size=1000))\n",
    "        j = 0\n",
    "        for train_index, val_index in kf.split(X_other):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            X_train_prep = preprocessor.fit_transform(X_train)\n",
    "            X_val_prep = preprocessor.transform(X_val)\n",
    "            X_test_prep = preprocessor.transform(X_test)\n",
    "            clf.fit(X_train_prep, y_train)\n",
    "            \n",
    "            y_train_pred = clf.predict(X_train_prep)\n",
    "            prec = precision_score(y_train, y_train_pred, average=\"macro\", zero_division=0)\n",
    "            rec = recall_score(y_train, y_train_pred, average=\"macro\")\n",
    "            f1 = f1_score(y_train, y_train_pred, average=\"macro\")\n",
    "         #   print('train:', i, \"precision score\", prec, \"recall score\", rec, \"f1 score\", f1)\n",
    "            train_scores[j][p] = f1\n",
    "            \n",
    "            y_val_pred = clf.predict(X_val_prep)\n",
    "            prec_val = precision_score(y_val, y_val_pred, average=\"macro\", zero_division=0)\n",
    "            rec_val = recall_score(y_val, y_val_pred, average=\"macro\")\n",
    "            f1_val = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "          #  print('validation:', i, \"precision score\", prec_val, \"recall score\", rec_val, \"f1 score\", f1_val)\n",
    "            val_scores[j][p] = f1_val\n",
    "            j += 1\n",
    "        models.append(clf) \n",
    "            \n",
    "        print('mean train f1 score:', np.mean(train_scores[:, p]), '    mean validation f1 score:', np.mean(val_scores[:, p]))\n",
    "    amax_mean = np.argmax(np.mean(val_scores, axis=0))\n",
    "    print('The best model parameters were:', param_grid[amax_mean])\n",
    "    print('The corresponding mean validation score is:',np.max(np.mean(val_scores, axis=0)))\n",
    "    final_models.append(models[amax_mean])\n",
    "    y_test_pred = final_models[-1].predict(X_test_prep)\n",
    "    test_scores[i] = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "    print('Test Score: ', test_scores[i])\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random state: 431 * 0\n",
      "working on params:   {'max_features': 15, 'max_depth': 15}\n",
      "mean train f1 score: 0.9706086773681125 mean validation f1 score: 0.6057641000240094\n",
      "working on params:   {'max_features': 20, 'max_depth': 15}\n",
      "mean train f1 score: 0.9693094336629514 mean validation f1 score: 0.6063666200834701\n",
      "working on params:   {'max_features': 25, 'max_depth': 15}\n",
      "mean train f1 score: 0.9699166184068558 mean validation f1 score: 0.6068555807340391\n",
      "working on params:   {'max_features': 30, 'max_depth': 15}\n",
      "mean train f1 score: 0.9709466212179398 mean validation f1 score: 0.6100749534105043\n",
      "working on params:   {'max_features': 35, 'max_depth': 15}\n",
      "mean train f1 score: 0.9702581398932802 mean validation f1 score: 0.6052003623426836\n",
      "working on params:   {'max_features': 40, 'max_depth': 15}\n",
      "mean train f1 score: 0.969100747780782 mean validation f1 score: 0.6012020766671179\n",
      "working on params:   {'max_features': 45, 'max_depth': 15}\n",
      "mean train f1 score: 0.9706105925967108 mean validation f1 score: 0.6040270541141028\n",
      "working on params:   {'max_features': 51, 'max_depth': 15}\n",
      "mean train f1 score: 0.9709898403066237 mean validation f1 score: 0.6105094231172431\n",
      "working on params:   {'max_features': 15, 'max_depth': 20}\n",
      "mean train f1 score: 0.988807553007596 mean validation f1 score: 0.6260642215093354\n",
      "working on params:   {'max_features': 20, 'max_depth': 20}\n",
      "mean train f1 score: 0.9884961901401029 mean validation f1 score: 0.6222051332193923\n",
      "working on params:   {'max_features': 25, 'max_depth': 20}\n",
      "mean train f1 score: 0.9887036978942673 mean validation f1 score: 0.6227700070433131\n",
      "working on params:   {'max_features': 30, 'max_depth': 20}\n",
      "mean train f1 score: 0.9885050912752427 mean validation f1 score: 0.6195579364000187\n",
      "working on params:   {'max_features': 35, 'max_depth': 20}\n",
      "mean train f1 score: 0.988523379392733 mean validation f1 score: 0.6192066064549151\n",
      "working on params:   {'max_features': 40, 'max_depth': 20}\n",
      "mean train f1 score: 0.9884320820231887 mean validation f1 score: 0.6258964720095386\n",
      "working on params:   {'max_features': 45, 'max_depth': 20}\n",
      "mean train f1 score: 0.9884006265285619 mean validation f1 score: 0.6200887504924137\n",
      "working on params:   {'max_features': 51, 'max_depth': 20}\n",
      "mean train f1 score: 0.9886675665446316 mean validation f1 score: 0.6206281050518545\n",
      "working on params:   {'max_features': 15, 'max_depth': 25}\n",
      "mean train f1 score: 0.9888345189164212 mean validation f1 score: 0.6226251876295821\n",
      "working on params:   {'max_features': 20, 'max_depth': 25}\n",
      "mean train f1 score: 0.988924502705087 mean validation f1 score: 0.6264780444230964\n",
      "working on params:   {'max_features': 25, 'max_depth': 25}\n",
      "mean train f1 score: 0.9888773862456448 mean validation f1 score: 0.6242885888805968\n",
      "working on params:   {'max_features': 30, 'max_depth': 25}\n",
      "mean train f1 score: 0.9889707767200634 mean validation f1 score: 0.6249901603855921\n",
      "working on params:   {'max_features': 35, 'max_depth': 25}\n",
      "mean train f1 score: 0.9888349416981183 mean validation f1 score: 0.619706221773355\n",
      "working on params:   {'max_features': 40, 'max_depth': 25}\n",
      "mean train f1 score: 0.9888341817183746 mean validation f1 score: 0.6239687202070535\n",
      "working on params:   {'max_features': 45, 'max_depth': 25}\n",
      "mean train f1 score: 0.9887798510907446 mean validation f1 score: 0.6209296331371709\n",
      "working on params:   {'max_features': 51, 'max_depth': 25}\n",
      "mean train f1 score: 0.9889241098752963 mean validation f1 score: 0.6260557226947525\n",
      "working on params:   {'max_features': 15, 'max_depth': 30}\n",
      "mean train f1 score: 0.9888367617234499 mean validation f1 score: 0.6233034343008572\n",
      "working on params:   {'max_features': 20, 'max_depth': 30}\n",
      "mean train f1 score: 0.9889340872682669 mean validation f1 score: 0.6249359385040721\n",
      "working on params:   {'max_features': 25, 'max_depth': 30}\n",
      "mean train f1 score: 0.9888773751380072 mean validation f1 score: 0.6257933703899322\n",
      "working on params:   {'max_features': 30, 'max_depth': 30}\n",
      "mean train f1 score: 0.9889256912581681 mean validation f1 score: 0.6237797717587631\n",
      "working on params:   {'max_features': 35, 'max_depth': 30}\n",
      "mean train f1 score: 0.9888313706416364 mean validation f1 score: 0.6232280358331659\n",
      "working on params:   {'max_features': 40, 'max_depth': 30}\n",
      "mean train f1 score: 0.9888394057877246 mean validation f1 score: 0.6211589597605301\n",
      "working on params:   {'max_features': 45, 'max_depth': 30}\n",
      "mean train f1 score: 0.9889261688299412 mean validation f1 score: 0.6236175655013707\n",
      "working on params:   {'max_features': 51, 'max_depth': 30}\n",
      "mean train f1 score: 0.9889289074354988 mean validation f1 score: 0.621105678424536\n",
      "working on params:   {'max_features': 15, 'max_depth': 35}\n",
      "mean train f1 score: 0.9888367617234499 mean validation f1 score: 0.6263721229190466\n",
      "working on params:   {'max_features': 20, 'max_depth': 35}\n",
      "mean train f1 score: 0.9889323077171815 mean validation f1 score: 0.6273082604920162\n",
      "working on params:   {'max_features': 25, 'max_depth': 35}\n",
      "mean train f1 score: 0.9888773751380072 mean validation f1 score: 0.6248325027485472\n",
      "working on params:   {'max_features': 30, 'max_depth': 35}\n",
      "mean train f1 score: 0.9889256912581681 mean validation f1 score: 0.6249083877189321\n",
      "working on params:   {'max_features': 35, 'max_depth': 35}\n",
      "mean train f1 score: 0.9888325003802636 mean validation f1 score: 0.6211128607221481\n",
      "working on params:   {'max_features': 40, 'max_depth': 35}\n",
      "mean train f1 score: 0.9888394057877246 mean validation f1 score: 0.620403640912809\n",
      "working on params:   {'max_features': 45, 'max_depth': 35}\n",
      "mean train f1 score: 0.9889260388478088 mean validation f1 score: 0.6215812578151089\n",
      "working on params:   {'max_features': 51, 'max_depth': 35}\n",
      "mean train f1 score: 0.9889289074354988 mean validation f1 score: 0.6211155158175221\n",
      "working on params:   {'max_features': 15, 'max_depth': 40}\n",
      "mean train f1 score: 0.9888367617234499 mean validation f1 score: 0.6262837701626008\n",
      "working on params:   {'max_features': 20, 'max_depth': 40}\n",
      "mean train f1 score: 0.9889323077171815 mean validation f1 score: 0.6274739847304995\n",
      "working on params:   {'max_features': 25, 'max_depth': 40}\n",
      "mean train f1 score: 0.9888773751380072 mean validation f1 score: 0.625456444727897\n",
      "working on params:   {'max_features': 30, 'max_depth': 40}\n",
      "mean train f1 score: 0.9889256912581681 mean validation f1 score: 0.6249709126921367\n",
      "working on params:   {'max_features': 35, 'max_depth': 40}\n",
      "mean train f1 score: 0.9888325003802636 mean validation f1 score: 0.6211128607221481\n",
      "working on params:   {'max_features': 40, 'max_depth': 40}\n",
      "mean train f1 score: 0.9888394057877246 mean validation f1 score: 0.6203255991197796\n",
      "working on params:   {'max_features': 45, 'max_depth': 40}\n",
      "mean train f1 score: 0.9889260388478088 mean validation f1 score: 0.6226334178975621\n",
      "working on params:   {'max_features': 51, 'max_depth': 40}\n",
      "mean train f1 score: 0.9889289074354988 mean validation f1 score: 0.6213103719767112\n",
      "The best model parameters were: {'max_features': 20, 'max_depth': 40}\n",
      "The corresponding mean validation score is: 0.6274739847304995\n",
      "Test Score:  0.8716395467418775\n",
      "random state: 431 * 1\n",
      "working on params:   {'max_features': 15, 'max_depth': 15}\n",
      "mean train f1 score: 0.9688401364520711 mean validation f1 score: 0.603727380013337\n",
      "working on params:   {'max_features': 20, 'max_depth': 15}\n",
      "mean train f1 score: 0.9689757958067207 mean validation f1 score: 0.606304948966684\n",
      "working on params:   {'max_features': 25, 'max_depth': 15}\n",
      "mean train f1 score: 0.9696728410621879 mean validation f1 score: 0.6038796102242359\n",
      "working on params:   {'max_features': 30, 'max_depth': 15}\n",
      "mean train f1 score: 0.9694529745682811 mean validation f1 score: 0.6022735623230883\n",
      "working on params:   {'max_features': 35, 'max_depth': 15}\n",
      "mean train f1 score: 0.9693873419695198 mean validation f1 score: 0.5998711124866859\n",
      "working on params:   {'max_features': 40, 'max_depth': 15}\n",
      "mean train f1 score: 0.969803314086448 mean validation f1 score: 0.6051976411942682\n",
      "working on params:   {'max_features': 45, 'max_depth': 15}\n",
      "mean train f1 score: 0.9679547193369047 mean validation f1 score: 0.5995673430436\n",
      "working on params:   {'max_features': 51, 'max_depth': 15}\n",
      "mean train f1 score: 0.9681728722902673 mean validation f1 score: 0.6034324614166754\n",
      "working on params:   {'max_features': 15, 'max_depth': 20}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train f1 score: 0.9883349953366736 mean validation f1 score: 0.6148239665652093\n",
      "working on params:   {'max_features': 20, 'max_depth': 20}\n",
      "mean train f1 score: 0.9884503495601563 mean validation f1 score: 0.6188052330813328\n",
      "working on params:   {'max_features': 25, 'max_depth': 20}\n",
      "mean train f1 score: 0.988477366094987 mean validation f1 score: 0.6164139244110325\n",
      "working on params:   {'max_features': 30, 'max_depth': 20}\n",
      "mean train f1 score: 0.9883963540158724 mean validation f1 score: 0.6167458944215195\n",
      "working on params:   {'max_features': 35, 'max_depth': 20}\n",
      "mean train f1 score: 0.9885481473097927 mean validation f1 score: 0.6156524711690121\n",
      "working on params:   {'max_features': 40, 'max_depth': 20}\n",
      "mean train f1 score: 0.9883634860212205 mean validation f1 score: 0.6129063424482906\n",
      "working on params:   {'max_features': 45, 'max_depth': 20}\n",
      "mean train f1 score: 0.9884846014640484 mean validation f1 score: 0.6172994291638938\n",
      "working on params:   {'max_features': 51, 'max_depth': 20}\n",
      "mean train f1 score: 0.9879474928804322 mean validation f1 score: 0.6148627498417665\n",
      "working on params:   {'max_features': 15, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886605778225691 mean validation f1 score: 0.6197516668095331\n",
      "working on params:   {'max_features': 20, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886624398238024 mean validation f1 score: 0.6174058711398961\n",
      "working on params:   {'max_features': 25, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886368742410309 mean validation f1 score: 0.6217111354737513\n",
      "working on params:   {'max_features': 30, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886410536405527 mean validation f1 score: 0.6225142640627295\n",
      "working on params:   {'max_features': 35, 'max_depth': 25}\n",
      "mean train f1 score: 0.988641019345362 mean validation f1 score: 0.6176384493703675\n",
      "working on params:   {'max_features': 40, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886401101747652 mean validation f1 score: 0.6216203999103921\n",
      "working on params:   {'max_features': 45, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886405074108184 mean validation f1 score: 0.619505002271062\n",
      "working on params:   {'max_features': 51, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886379368169871 mean validation f1 score: 0.6143570560694022\n",
      "working on params:   {'max_features': 15, 'max_depth': 30}\n",
      "mean train f1 score: 0.9886399761136518 mean validation f1 score: 0.6181680880555087\n",
      "working on params:   {'max_features': 20, 'max_depth': 30}\n",
      "mean train f1 score: 0.9886393295481928 mean validation f1 score: 0.6187104933956636\n",
      "working on params:   {'max_features': 25, 'max_depth': 30}\n",
      "mean train f1 score: 0.9886424733438904 mean validation f1 score: 0.6171495202890865\n",
      "working on params:   {'max_features': 30, 'max_depth': 30}\n",
      "mean train f1 score: 0.988642214116238 mean validation f1 score: 0.6218883682107441\n",
      "working on params:   {'max_features': 35, 'max_depth': 30}\n",
      "mean train f1 score: 0.9886393342221249 mean validation f1 score: 0.6127694687887705\n",
      "working on params:   {'max_features': 40, 'max_depth': 30}\n",
      "mean train f1 score: 0.9886402372323759 mean validation f1 score: 0.6171073516293532\n",
      "working on params:   {'max_features': 45, 'max_depth': 30}\n",
      "mean train f1 score: 0.988636507616649 mean validation f1 score: 0.6171603892394638\n",
      "working on params:   {'max_features': 51, 'max_depth': 30}\n",
      "mean train f1 score: 0.9886416047947688 mean validation f1 score: 0.6159233180896639\n",
      "working on params:   {'max_features': 15, 'max_depth': 35}\n",
      "mean train f1 score: 0.9886396718739435 mean validation f1 score: 0.6192379238751636\n",
      "working on params:   {'max_features': 20, 'max_depth': 35}\n",
      "mean train f1 score: 0.9886393295481928 mean validation f1 score: 0.6195617269876112\n",
      "working on params:   {'max_features': 25, 'max_depth': 35}\n",
      "mean train f1 score: 0.9886424733438904 mean validation f1 score: 0.6177732778599055\n",
      "working on params:   {'max_features': 30, 'max_depth': 35}\n",
      "mean train f1 score: 0.988642214116238 mean validation f1 score: 0.618431744593871\n",
      "working on params:   {'max_features': 35, 'max_depth': 35}\n",
      "mean train f1 score: 0.9886387412964339 mean validation f1 score: 0.6135209144707261\n",
      "working on params:   {'max_features': 40, 'max_depth': 35}\n",
      "mean train f1 score: 0.9886402372323759 mean validation f1 score: 0.6183637247200714\n",
      "working on params:   {'max_features': 45, 'max_depth': 35}\n",
      "mean train f1 score: 0.98863897243958 mean validation f1 score: 0.6177130026866186\n",
      "working on params:   {'max_features': 51, 'max_depth': 35}\n",
      "mean train f1 score: 0.9886416047947688 mean validation f1 score: 0.6174497903490029\n",
      "working on params:   {'max_features': 15, 'max_depth': 40}\n",
      "mean train f1 score: 0.9886396718739435 mean validation f1 score: 0.6192351086836148\n",
      "working on params:   {'max_features': 20, 'max_depth': 40}\n",
      "mean train f1 score: 0.9886397491899472 mean validation f1 score: 0.6198178154692018\n",
      "working on params:   {'max_features': 25, 'max_depth': 40}\n",
      "mean train f1 score: 0.9886424733438904 mean validation f1 score: 0.617848759157144\n",
      "working on params:   {'max_features': 30, 'max_depth': 40}\n",
      "mean train f1 score: 0.988642214116238 mean validation f1 score: 0.618431744593871\n",
      "working on params:   {'max_features': 35, 'max_depth': 40}\n",
      "mean train f1 score: 0.9886387412964339 mean validation f1 score: 0.6140747560009988\n",
      "working on params:   {'max_features': 40, 'max_depth': 40}\n",
      "mean train f1 score: 0.9886402372323759 mean validation f1 score: 0.6186721181180688\n",
      "working on params:   {'max_features': 45, 'max_depth': 40}\n",
      "mean train f1 score: 0.98863897243958 mean validation f1 score: 0.6175077854044558\n",
      "working on params:   {'max_features': 51, 'max_depth': 40}\n",
      "mean train f1 score: 0.9886416047947688 mean validation f1 score: 0.6163374834732243\n",
      "The best model parameters were: {'max_features': 30, 'max_depth': 25}\n",
      "The corresponding mean validation score is: 0.6225142640627295\n",
      "Test Score:  0.8723025944145725\n",
      "random state: 431 * 2\n",
      "working on params:   {'max_features': 15, 'max_depth': 15}\n",
      "mean train f1 score: 0.9694385555195052 mean validation f1 score: 0.612281140757859\n",
      "working on params:   {'max_features': 20, 'max_depth': 15}\n",
      "mean train f1 score: 0.9706281748563915 mean validation f1 score: 0.6115903636730531\n",
      "working on params:   {'max_features': 25, 'max_depth': 15}\n",
      "mean train f1 score: 0.9685483209877954 mean validation f1 score: 0.6084450201994337\n",
      "working on params:   {'max_features': 30, 'max_depth': 15}\n",
      "mean train f1 score: 0.9691555791442454 mean validation f1 score: 0.6126963611548328\n",
      "working on params:   {'max_features': 35, 'max_depth': 15}\n",
      "mean train f1 score: 0.9691573332596917 mean validation f1 score: 0.6063097836373745\n",
      "working on params:   {'max_features': 40, 'max_depth': 15}\n",
      "mean train f1 score: 0.9687327709807374 mean validation f1 score: 0.6089366841336031\n",
      "working on params:   {'max_features': 45, 'max_depth': 15}\n",
      "mean train f1 score: 0.9685299349592581 mean validation f1 score: 0.6117860297300542\n",
      "working on params:   {'max_features': 51, 'max_depth': 15}\n",
      "mean train f1 score: 0.9688319203742191 mean validation f1 score: 0.6111904632273747\n",
      "working on params:   {'max_features': 15, 'max_depth': 20}\n",
      "mean train f1 score: 0.9881434053891678 mean validation f1 score: 0.6289376895413059\n",
      "working on params:   {'max_features': 20, 'max_depth': 20}\n",
      "mean train f1 score: 0.9882669782465039 mean validation f1 score: 0.6290562023763671\n",
      "working on params:   {'max_features': 25, 'max_depth': 20}\n",
      "mean train f1 score: 0.9881922724206741 mean validation f1 score: 0.6326636348446235\n",
      "working on params:   {'max_features': 30, 'max_depth': 20}\n",
      "mean train f1 score: 0.9880311655824418 mean validation f1 score: 0.6312657787407016\n",
      "working on params:   {'max_features': 35, 'max_depth': 20}\n",
      "mean train f1 score: 0.9881049396234027 mean validation f1 score: 0.6295976536036788\n",
      "working on params:   {'max_features': 40, 'max_depth': 20}\n",
      "mean train f1 score: 0.9880443946977252 mean validation f1 score: 0.6296156111093874\n",
      "working on params:   {'max_features': 45, 'max_depth': 20}\n",
      "mean train f1 score: 0.9880677040951228 mean validation f1 score: 0.6289625586948538\n",
      "working on params:   {'max_features': 51, 'max_depth': 20}\n",
      "mean train f1 score: 0.9880858439538358 mean validation f1 score: 0.629929525135367\n",
      "working on params:   {'max_features': 15, 'max_depth': 25}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train f1 score: 0.988418946525428 mean validation f1 score: 0.6314706710170386\n",
      "working on params:   {'max_features': 20, 'max_depth': 25}\n",
      "mean train f1 score: 0.9884200197534511 mean validation f1 score: 0.6299696506766109\n",
      "working on params:   {'max_features': 25, 'max_depth': 25}\n",
      "mean train f1 score: 0.9885639502521673 mean validation f1 score: 0.6301643188638043\n",
      "working on params:   {'max_features': 30, 'max_depth': 25}\n",
      "mean train f1 score: 0.9885656333593675 mean validation f1 score: 0.632387625524575\n",
      "working on params:   {'max_features': 35, 'max_depth': 25}\n",
      "mean train f1 score: 0.9883838572760943 mean validation f1 score: 0.6307768614605387\n",
      "working on params:   {'max_features': 40, 'max_depth': 25}\n",
      "mean train f1 score: 0.9884254766314261 mean validation f1 score: 0.6295425885435982\n",
      "working on params:   {'max_features': 45, 'max_depth': 25}\n",
      "mean train f1 score: 0.9885296310798196 mean validation f1 score: 0.6297251447071781\n",
      "working on params:   {'max_features': 51, 'max_depth': 25}\n",
      "mean train f1 score: 0.9885142479706851 mean validation f1 score: 0.6311765386286685\n",
      "working on params:   {'max_features': 15, 'max_depth': 30}\n",
      "mean train f1 score: 0.9884197396408684 mean validation f1 score: 0.6298461361512435\n",
      "working on params:   {'max_features': 20, 'max_depth': 30}\n",
      "mean train f1 score: 0.9884205453459974 mean validation f1 score: 0.6269638784663899\n",
      "working on params:   {'max_features': 25, 'max_depth': 30}\n",
      "mean train f1 score: 0.9885642800011005 mean validation f1 score: 0.6307397372587089\n",
      "working on params:   {'max_features': 30, 'max_depth': 30}\n",
      "mean train f1 score: 0.9885721725879097 mean validation f1 score: 0.6281016523094334\n",
      "working on params:   {'max_features': 35, 'max_depth': 30}\n",
      "mean train f1 score: 0.9884251385553641 mean validation f1 score: 0.6336176342226897\n",
      "working on params:   {'max_features': 40, 'max_depth': 30}\n",
      "mean train f1 score: 0.9884239955639014 mean validation f1 score: 0.6302310544016402\n",
      "working on params:   {'max_features': 45, 'max_depth': 30}\n",
      "mean train f1 score: 0.9885700542856154 mean validation f1 score: 0.6317711016753927\n",
      "working on params:   {'max_features': 51, 'max_depth': 30}\n",
      "mean train f1 score: 0.9885171679016246 mean validation f1 score: 0.6315627593189543\n",
      "working on params:   {'max_features': 15, 'max_depth': 35}\n",
      "mean train f1 score: 0.9884197396408684 mean validation f1 score: 0.630158526006065\n",
      "working on params:   {'max_features': 20, 'max_depth': 35}\n",
      "mean train f1 score: 0.9884205453459974 mean validation f1 score: 0.6271574605655387\n",
      "working on params:   {'max_features': 25, 'max_depth': 35}\n",
      "mean train f1 score: 0.9885665227040827 mean validation f1 score: 0.6299641858359268\n",
      "working on params:   {'max_features': 30, 'max_depth': 35}\n",
      "mean train f1 score: 0.9885721725879097 mean validation f1 score: 0.6299193061039233\n",
      "working on params:   {'max_features': 35, 'max_depth': 35}\n",
      "mean train f1 score: 0.988424683275334 mean validation f1 score: 0.6334457786224772\n",
      "working on params:   {'max_features': 40, 'max_depth': 35}\n",
      "mean train f1 score: 0.9884224529793264 mean validation f1 score: 0.6292859567710501\n",
      "working on params:   {'max_features': 45, 'max_depth': 35}\n",
      "mean train f1 score: 0.9885700542856154 mean validation f1 score: 0.6280420352477406\n",
      "working on params:   {'max_features': 51, 'max_depth': 35}\n",
      "mean train f1 score: 0.9885171679016246 mean validation f1 score: 0.6306306614320077\n",
      "working on params:   {'max_features': 15, 'max_depth': 40}\n",
      "mean train f1 score: 0.9884197396408684 mean validation f1 score: 0.630158526006065\n",
      "working on params:   {'max_features': 20, 'max_depth': 40}\n",
      "mean train f1 score: 0.9884205453459974 mean validation f1 score: 0.6273467790814893\n",
      "working on params:   {'max_features': 25, 'max_depth': 40}\n",
      "mean train f1 score: 0.9885665227040827 mean validation f1 score: 0.6299641858359268\n",
      "working on params:   {'max_features': 30, 'max_depth': 40}\n",
      "mean train f1 score: 0.9885721725879097 mean validation f1 score: 0.6299193061039233\n",
      "working on params:   {'max_features': 35, 'max_depth': 40}\n",
      "mean train f1 score: 0.988424683275334 mean validation f1 score: 0.6335748550733914\n",
      "working on params:   {'max_features': 40, 'max_depth': 40}\n",
      "mean train f1 score: 0.9884224529793264 mean validation f1 score: 0.629481313330964\n",
      "working on params:   {'max_features': 45, 'max_depth': 40}\n",
      "mean train f1 score: 0.9885700542856154 mean validation f1 score: 0.628381940747738\n",
      "working on params:   {'max_features': 51, 'max_depth': 40}\n",
      "mean train f1 score: 0.9885171679016246 mean validation f1 score: 0.6306306614320077\n",
      "The best model parameters were: {'max_features': 35, 'max_depth': 30}\n",
      "The corresponding mean validation score is: 0.6336176342226897\n",
      "Test Score:  0.8680824842642464\n",
      "random state: 431 * 3\n",
      "working on params:   {'max_features': 15, 'max_depth': 15}\n",
      "mean train f1 score: 0.9707661426380967 mean validation f1 score: 0.6116199914295939\n",
      "working on params:   {'max_features': 20, 'max_depth': 15}\n",
      "mean train f1 score: 0.9696937820951573 mean validation f1 score: 0.6096449580728605\n",
      "working on params:   {'max_features': 25, 'max_depth': 15}\n",
      "mean train f1 score: 0.968665027542992 mean validation f1 score: 0.6059584744747293\n",
      "working on params:   {'max_features': 30, 'max_depth': 15}\n",
      "mean train f1 score: 0.9675327617131703 mean validation f1 score: 0.6084326867028749\n",
      "working on params:   {'max_features': 35, 'max_depth': 15}\n",
      "mean train f1 score: 0.967871554308917 mean validation f1 score: 0.6085688918000955\n",
      "working on params:   {'max_features': 40, 'max_depth': 15}\n",
      "mean train f1 score: 0.9681390901484808 mean validation f1 score: 0.6136008809340419\n",
      "working on params:   {'max_features': 45, 'max_depth': 15}\n",
      "mean train f1 score: 0.966447656064817 mean validation f1 score: 0.6130492057287363\n",
      "working on params:   {'max_features': 51, 'max_depth': 15}\n",
      "mean train f1 score: 0.9671607251655975 mean validation f1 score: 0.6122845877412924\n",
      "working on params:   {'max_features': 15, 'max_depth': 20}\n",
      "mean train f1 score: 0.9883645190167144 mean validation f1 score: 0.6232075463892617\n",
      "working on params:   {'max_features': 20, 'max_depth': 20}\n",
      "mean train f1 score: 0.9884138999617293 mean validation f1 score: 0.6277392788931585\n",
      "working on params:   {'max_features': 25, 'max_depth': 20}\n",
      "mean train f1 score: 0.98853655023095 mean validation f1 score: 0.6234533537253005\n",
      "working on params:   {'max_features': 30, 'max_depth': 20}\n",
      "mean train f1 score: 0.9885149583918754 mean validation f1 score: 0.6239587275859956\n",
      "working on params:   {'max_features': 35, 'max_depth': 20}\n",
      "mean train f1 score: 0.9881788871690174 mean validation f1 score: 0.6310595780326123\n",
      "working on params:   {'max_features': 40, 'max_depth': 20}\n",
      "mean train f1 score: 0.9879190578059753 mean validation f1 score: 0.624788057832089\n",
      "working on params:   {'max_features': 45, 'max_depth': 20}\n",
      "mean train f1 score: 0.9881318507635433 mean validation f1 score: 0.6214600844488825\n",
      "working on params:   {'max_features': 51, 'max_depth': 20}\n",
      "mean train f1 score: 0.988393518287632 mean validation f1 score: 0.6286985479720154\n",
      "working on params:   {'max_features': 15, 'max_depth': 25}\n",
      "mean train f1 score: 0.9887200728336055 mean validation f1 score: 0.6257167507332514\n",
      "working on params:   {'max_features': 20, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886922817392664 mean validation f1 score: 0.6260443560849926\n",
      "working on params:   {'max_features': 25, 'max_depth': 25}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4ee4a3f27136>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mX_val_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mX_test_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/skmultilearn/problem_transform/lp.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         self.classifier.fit(self._ensure_input_format(X),\n\u001b[0;32m--> 141\u001b[0;31m                             self.transform(y))\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 392\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                                         indices=indices)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/miniconda3/envs/data1030/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {  'max_depth': [15, 20, 25, 30, 35, 40], # 5, 7, \n",
    "                'max_features': [15, 20, 25, 30, 35, 40, 45, 51]} # 4, 8, \n",
    "\n",
    "param_grid = ParameterGrid(param_grid)\n",
    "test_scores = np.zeros(10)\n",
    "final_models = []\n",
    "\n",
    "for i in range(10):\n",
    "    random_state = 431 * i \n",
    "    print('random state: 431 * {}'.format(i))\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "            \n",
    "    models = []\n",
    "    train_scores = np.zeros(shape=(4, len(param_grid)))\n",
    "    val_scores = np.zeros(shape=(4, len(param_grid)))\n",
    "    \n",
    "    for p in range(len(param_grid)):\n",
    "        params = param_grid[p]\n",
    "        print('working on params:  ', params) \n",
    "        clf = LabelPowerset(RandomForestClassifier(**params,random_state=random_state))\n",
    "        j = 0\n",
    "        for train_index, val_index in kf.split(X_other):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            X_train_prep = preprocessor.fit_transform(X_train)\n",
    "            X_val_prep = preprocessor.transform(X_val)\n",
    "            X_test_prep = preprocessor.transform(X_test)\n",
    "            clf.fit(X_train_prep, y_train)\n",
    "            \n",
    "            y_train_pred = clf.predict(X_train_prep)\n",
    "            prec = precision_score(y_train, y_train_pred, average=\"macro\", zero_division=0)\n",
    "            rec = recall_score(y_train, y_train_pred, average=\"macro\")\n",
    "            f1 = f1_score(y_train, y_train_pred, average=\"macro\")\n",
    "         #   print('train:', i, \"precision score\", prec, \"recall score\", rec, \"f1 score\", f1)\n",
    "            train_scores[j][p] = f1\n",
    "            \n",
    "            y_val_pred = clf.predict(X_val_prep)\n",
    "            prec_val = precision_score(y_val, y_val_pred, average=\"macro\", zero_division=0)\n",
    "            rec_val = recall_score(y_val, y_val_pred, average=\"macro\")\n",
    "            f1_val = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "          #  print('validation:', i, \"precision score\", prec_val, \"recall score\", rec_val, \"f1 score\", f1_val)\n",
    "            val_scores[j][p] = f1_val\n",
    "            j += 1\n",
    "        models.append(clf) \n",
    "            \n",
    "        print('mean train f1 score:', np.mean(train_scores[:, p]), '    mean validation f1 score:', np.mean(val_scores[:, p]))\n",
    "    amax_mean = np.argmax(np.mean(val_scores, axis=0))\n",
    "    print('The best model parameters were:', param_grid[amax_mean])\n",
    "    print('The corresponding mean validation score is:',np.max(np.mean(val_scores, axis=0)))\n",
    "    final_models.append(models[amax_mean])\n",
    "    y_test_pred = final_models[-1].predict(X_test_prep)\n",
    "    test_scores[i] = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "    print('Test Score: ', test_scores[i])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random state: 700 * 0\n",
      "working on params:   {'max_features': 27, 'max_depth': 25}\n",
      "mean train f1 score: 0.9888331374317167     mean validation f1 score: 0.6232604101330355\n",
      "working on params:   {'max_features': 35, 'max_depth': 25}\n",
      "mean train f1 score: 0.9888349416981183     mean validation f1 score: 0.619706221773355\n",
      "working on params:   {'max_features': 43, 'max_depth': 25}\n",
      "mean train f1 score: 0.9889282109841334     mean validation f1 score: 0.6204870248606764\n",
      "working on params:   {'max_features': 51, 'max_depth': 25}\n",
      "mean train f1 score: 0.9889241098752963     mean validation f1 score: 0.6260557226947525\n",
      "working on params:   {'max_features': 27, 'max_depth': 30}\n",
      "mean train f1 score: 0.9888376896912703     mean validation f1 score: 0.6209472468792516\n",
      "working on params:   {'max_features': 35, 'max_depth': 30}\n",
      "mean train f1 score: 0.9888313706416364     mean validation f1 score: 0.6232280358331659\n",
      "working on params:   {'max_features': 43, 'max_depth': 30}\n",
      "mean train f1 score: 0.9889254537933755     mean validation f1 score: 0.6210373375177389\n",
      "working on params:   {'max_features': 51, 'max_depth': 30}\n",
      "mean train f1 score: 0.9889289074354988     mean validation f1 score: 0.621105678424536\n",
      "working on params:   {'max_features': 27, 'max_depth': 35}\n",
      "mean train f1 score: 0.9888376896912703     mean validation f1 score: 0.6248832873661779\n",
      "working on params:   {'max_features': 35, 'max_depth': 35}\n",
      "mean train f1 score: 0.9888325003802636     mean validation f1 score: 0.6211128607221481\n",
      "working on params:   {'max_features': 43, 'max_depth': 35}\n",
      "mean train f1 score: 0.9889254537933755     mean validation f1 score: 0.622378617414576\n",
      "working on params:   {'max_features': 51, 'max_depth': 35}\n",
      "mean train f1 score: 0.9889289074354988     mean validation f1 score: 0.6211155158175221\n",
      "The best model parameters were: {'max_features': 51, 'max_depth': 25}\n",
      "The corresponding mean validation score is: 0.6260557226947525\n",
      "Test Score:  0.8733443856611928\n",
      "random state: 700 * 1\n",
      "working on params:   {'max_features': 27, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886898468721784     mean validation f1 score: 0.6260196872907872\n",
      "working on params:   {'max_features': 35, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886883820946853     mean validation f1 score: 0.6247036912490894\n",
      "working on params:   {'max_features': 43, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886871714101502     mean validation f1 score: 0.6211241169398373\n",
      "working on params:   {'max_features': 51, 'max_depth': 25}\n",
      "mean train f1 score: 0.988690377580561     mean validation f1 score: 0.6212944340228317\n",
      "working on params:   {'max_features': 27, 'max_depth': 30}\n",
      "mean train f1 score: 0.988690156226163     mean validation f1 score: 0.6249535553939721\n",
      "working on params:   {'max_features': 35, 'max_depth': 30}\n",
      "mean train f1 score: 0.9886907565080721     mean validation f1 score: 0.6237668995860437\n",
      "working on params:   {'max_features': 43, 'max_depth': 30}\n",
      "mean train f1 score: 0.9886893476665052     mean validation f1 score: 0.6206928837331546\n",
      "working on params:   {'max_features': 51, 'max_depth': 30}\n",
      "mean train f1 score: 0.9886910614371891     mean validation f1 score: 0.6192580097781815\n",
      "working on params:   {'max_features': 27, 'max_depth': 35}\n",
      "mean train f1 score: 0.9886886598599709     mean validation f1 score: 0.6282035486946628\n",
      "working on params:   {'max_features': 35, 'max_depth': 35}\n",
      "mean train f1 score: 0.9886907565080721     mean validation f1 score: 0.6237511743303665\n",
      "working on params:   {'max_features': 43, 'max_depth': 35}\n",
      "mean train f1 score: 0.9886893476665052     mean validation f1 score: 0.6207266399412424\n",
      "working on params:   {'max_features': 51, 'max_depth': 35}\n",
      "mean train f1 score: 0.9886918899426544     mean validation f1 score: 0.6188231030199093\n",
      "The best model parameters were: {'max_features': 27, 'max_depth': 35}\n",
      "The corresponding mean validation score is: 0.6282035486946628\n",
      "Test Score:  0.887164562408855\n",
      "random state: 700 * 2\n",
      "working on params:   {'max_features': 27, 'max_depth': 25}\n",
      "mean train f1 score: 0.9891694172242067     mean validation f1 score: 0.6106579653396913\n",
      "working on params:   {'max_features': 35, 'max_depth': 25}\n",
      "mean train f1 score: 0.9891701900960328     mean validation f1 score: 0.6183630807682982\n",
      "working on params:   {'max_features': 43, 'max_depth': 25}\n",
      "mean train f1 score: 0.9891688543161788     mean validation f1 score: 0.6142076862793548\n",
      "working on params:   {'max_features': 51, 'max_depth': 25}\n",
      "mean train f1 score: 0.9891675194202757     mean validation f1 score: 0.6180369829137073\n",
      "working on params:   {'max_features': 27, 'max_depth': 30}\n",
      "mean train f1 score: 0.9891710834648129     mean validation f1 score: 0.6120365810077799\n",
      "working on params:   {'max_features': 35, 'max_depth': 30}\n",
      "mean train f1 score: 0.9891717986081041     mean validation f1 score: 0.6194861495762198\n",
      "working on params:   {'max_features': 43, 'max_depth': 30}\n",
      "mean train f1 score: 0.9891721277279639     mean validation f1 score: 0.6146326905780765\n",
      "working on params:   {'max_features': 51, 'max_depth': 30}\n",
      "mean train f1 score: 0.9891694347972328     mean validation f1 score: 0.6166693629642259\n",
      "working on params:   {'max_features': 27, 'max_depth': 35}\n",
      "mean train f1 score: 0.9891710834648129     mean validation f1 score: 0.6123757370191767\n",
      "working on params:   {'max_features': 35, 'max_depth': 35}\n",
      "mean train f1 score: 0.9891717986081041     mean validation f1 score: 0.6198353573435805\n",
      "working on params:   {'max_features': 43, 'max_depth': 35}\n",
      "mean train f1 score: 0.9891741722982726     mean validation f1 score: 0.6132421325599714\n",
      "working on params:   {'max_features': 51, 'max_depth': 35}\n",
      "mean train f1 score: 0.9891700190661049     mean validation f1 score: 0.6164806141732411\n",
      "The best model parameters were: {'max_features': 35, 'max_depth': 35}\n",
      "The corresponding mean validation score is: 0.6198353573435805\n",
      "Test Score:  0.8668814081553363\n",
      "random state: 700 * 3\n",
      "working on params:   {'max_features': 27, 'max_depth': 25}\n",
      "mean train f1 score: 0.9888602782937332     mean validation f1 score: 0.6208572604027591\n",
      "working on params:   {'max_features': 35, 'max_depth': 25}\n",
      "mean train f1 score: 0.9887914557790897     mean validation f1 score: 0.6199195036032453\n",
      "working on params:   {'max_features': 43, 'max_depth': 25}\n",
      "mean train f1 score: 0.9887954680519278     mean validation f1 score: 0.6189375114718798\n",
      "working on params:   {'max_features': 51, 'max_depth': 25}\n",
      "mean train f1 score: 0.9887943627654526     mean validation f1 score: 0.6193763136580451\n",
      "working on params:   {'max_features': 27, 'max_depth': 30}\n",
      "mean train f1 score: 0.9887915005755645     mean validation f1 score: 0.6211548027095612\n",
      "working on params:   {'max_features': 35, 'max_depth': 30}\n",
      "mean train f1 score: 0.9887909668475818     mean validation f1 score: 0.6190973780981474\n",
      "working on params:   {'max_features': 43, 'max_depth': 30}\n",
      "mean train f1 score: 0.9887953011868762     mean validation f1 score: 0.6198658861568354\n",
      "working on params:   {'max_features': 51, 'max_depth': 30}\n",
      "mean train f1 score: 0.9887946140583335     mean validation f1 score: 0.621513962896558\n",
      "working on params:   {'max_features': 27, 'max_depth': 35}\n",
      "mean train f1 score: 0.9887942188947603     mean validation f1 score: 0.6185587185681835\n",
      "working on params:   {'max_features': 35, 'max_depth': 35}\n",
      "mean train f1 score: 0.9887909668475818     mean validation f1 score: 0.6176666926589273\n",
      "working on params:   {'max_features': 43, 'max_depth': 35}\n",
      "mean train f1 score: 0.9887944409851417     mean validation f1 score: 0.618724133702402\n",
      "working on params:   {'max_features': 51, 'max_depth': 35}\n",
      "mean train f1 score: 0.9887930936423951     mean validation f1 score: 0.6206729235040834\n",
      "The best model parameters were: {'max_features': 51, 'max_depth': 30}\n",
      "The corresponding mean validation score is: 0.621513962896558\n",
      "Test Score:  0.8839824389824615\n",
      "random state: 700 * 4\n",
      "working on params:   {'max_features': 27, 'max_depth': 25}\n",
      "mean train f1 score: 0.989167614619775     mean validation f1 score: 0.6187054118772032\n",
      "working on params:   {'max_features': 35, 'max_depth': 25}\n",
      "mean train f1 score: 0.9891480142677418     mean validation f1 score: 0.6199636694042384\n",
      "working on params:   {'max_features': 43, 'max_depth': 25}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train f1 score: 0.9891658119424833     mean validation f1 score: 0.6196198259508181\n",
      "working on params:   {'max_features': 51, 'max_depth': 25}\n",
      "mean train f1 score: 0.9891809681988171     mean validation f1 score: 0.6171713037536423\n",
      "working on params:   {'max_features': 27, 'max_depth': 30}\n",
      "mean train f1 score: 0.9890823649333008     mean validation f1 score: 0.6229033574296124\n",
      "working on params:   {'max_features': 35, 'max_depth': 30}\n",
      "mean train f1 score: 0.9891363743746321     mean validation f1 score: 0.6226952716986194\n",
      "working on params:   {'max_features': 43, 'max_depth': 30}\n",
      "mean train f1 score: 0.9891636091414272     mean validation f1 score: 0.6229229904228455\n",
      "working on params:   {'max_features': 51, 'max_depth': 30}\n",
      "mean train f1 score: 0.9891816898574083     mean validation f1 score: 0.6148727590726404\n",
      "working on params:   {'max_features': 27, 'max_depth': 35}\n",
      "mean train f1 score: 0.989081625175251     mean validation f1 score: 0.6234089309818479\n",
      "working on params:   {'max_features': 35, 'max_depth': 35}\n",
      "mean train f1 score: 0.9891363743746321     mean validation f1 score: 0.6229909775694751\n",
      "working on params:   {'max_features': 43, 'max_depth': 35}\n",
      "mean train f1 score: 0.9891636091414272     mean validation f1 score: 0.623701194401131\n",
      "working on params:   {'max_features': 51, 'max_depth': 35}\n",
      "mean train f1 score: 0.9891816898574083     mean validation f1 score: 0.6138812639911556\n",
      "The best model parameters were: {'max_features': 43, 'max_depth': 35}\n",
      "The corresponding mean validation score is: 0.623701194401131\n",
      "Test Score:  0.8738576489526162\n",
      "random state: 700 * 5\n",
      "working on params:   {'max_features': 27, 'max_depth': 25}\n",
      "mean train f1 score: 0.9892029933695633     mean validation f1 score: 0.6255282807767123\n",
      "working on params:   {'max_features': 35, 'max_depth': 25}\n",
      "mean train f1 score: 0.9891611315543994     mean validation f1 score: 0.6275993090914089\n",
      "working on params:   {'max_features': 43, 'max_depth': 25}\n",
      "mean train f1 score: 0.9891469745813122     mean validation f1 score: 0.6249044127734475\n",
      "working on params:   {'max_features': 51, 'max_depth': 25}\n",
      "mean train f1 score: 0.9891970038229678     mean validation f1 score: 0.6253003227951797\n",
      "working on params:   {'max_features': 27, 'max_depth': 30}\n",
      "mean train f1 score: 0.9892050045822824     mean validation f1 score: 0.6212680390465376\n",
      "working on params:   {'max_features': 35, 'max_depth': 30}\n",
      "mean train f1 score: 0.9891964163507575     mean validation f1 score: 0.6244022078380816\n",
      "working on params:   {'max_features': 43, 'max_depth': 30}\n",
      "mean train f1 score: 0.9891982305851582     mean validation f1 score: 0.6248655101757324\n",
      "working on params:   {'max_features': 51, 'max_depth': 30}\n",
      "mean train f1 score: 0.9891971387171279     mean validation f1 score: 0.6273571192791894\n",
      "working on params:   {'max_features': 27, 'max_depth': 35}\n",
      "mean train f1 score: 0.9892051636791314     mean validation f1 score: 0.6205068828631048\n",
      "working on params:   {'max_features': 35, 'max_depth': 35}\n",
      "mean train f1 score: 0.9891955533786471     mean validation f1 score: 0.6246517352422339\n",
      "working on params:   {'max_features': 43, 'max_depth': 35}\n",
      "mean train f1 score: 0.9891994071468936     mean validation f1 score: 0.6241720371577376\n",
      "working on params:   {'max_features': 51, 'max_depth': 35}\n",
      "mean train f1 score: 0.9891971387171279     mean validation f1 score: 0.6250261291991093\n",
      "The best model parameters were: {'max_features': 35, 'max_depth': 25}\n",
      "The corresponding mean validation score is: 0.6275993090914089\n",
      "Test Score:  0.8585422655653611\n",
      "random state: 700 * 6\n",
      "working on params:   {'max_features': 27, 'max_depth': 25}\n",
      "mean train f1 score: 0.9888506643696205     mean validation f1 score: 0.6180729593249948\n",
      "working on params:   {'max_features': 35, 'max_depth': 25}\n",
      "mean train f1 score: 0.9888545693746967     mean validation f1 score: 0.618526000250108\n",
      "working on params:   {'max_features': 43, 'max_depth': 25}\n",
      "mean train f1 score: 0.9888532016551248     mean validation f1 score: 0.6185280431727873\n",
      "working on params:   {'max_features': 51, 'max_depth': 25}\n",
      "mean train f1 score: 0.988853090605151     mean validation f1 score: 0.621492995965555\n",
      "working on params:   {'max_features': 27, 'max_depth': 30}\n",
      "mean train f1 score: 0.9888555920656629     mean validation f1 score: 0.6189100889043867\n",
      "working on params:   {'max_features': 35, 'max_depth': 30}\n",
      "mean train f1 score: 0.9888529852474055     mean validation f1 score: 0.6155609158681042\n",
      "working on params:   {'max_features': 43, 'max_depth': 30}\n",
      "mean train f1 score: 0.9888540025201481     mean validation f1 score: 0.6152127267932029\n",
      "working on params:   {'max_features': 51, 'max_depth': 30}\n",
      "mean train f1 score: 0.9888548162748859     mean validation f1 score: 0.6207981780100096\n",
      "working on params:   {'max_features': 27, 'max_depth': 35}\n",
      "mean train f1 score: 0.9888555920656629     mean validation f1 score: 0.6211446233835486\n",
      "working on params:   {'max_features': 35, 'max_depth': 35}\n",
      "mean train f1 score: 0.9888520577756933     mean validation f1 score: 0.6165750063573905\n",
      "working on params:   {'max_features': 43, 'max_depth': 35}\n",
      "mean train f1 score: 0.9888540025201481     mean validation f1 score: 0.6170369412015748\n",
      "working on params:   {'max_features': 51, 'max_depth': 35}\n",
      "mean train f1 score: 0.9888548162748859     mean validation f1 score: 0.6225628476834836\n",
      "The best model parameters were: {'max_features': 51, 'max_depth': 35}\n",
      "The corresponding mean validation score is: 0.6225628476834836\n",
      "Test Score:  0.8836308379506742\n",
      "random state: 700 * 7\n",
      "working on params:   {'max_features': 27, 'max_depth': 25}\n",
      "mean train f1 score: 0.9889944273704879     mean validation f1 score: 0.6213351959609933\n",
      "working on params:   {'max_features': 35, 'max_depth': 25}\n",
      "mean train f1 score: 0.9890657770417798     mean validation f1 score: 0.6190105190773956\n",
      "working on params:   {'max_features': 43, 'max_depth': 25}\n",
      "mean train f1 score: 0.9890464379203403     mean validation f1 score: 0.6155576842265807\n",
      "working on params:   {'max_features': 51, 'max_depth': 25}\n",
      "mean train f1 score: 0.9890446556961765     mean validation f1 score: 0.6168796495463665\n",
      "working on params:   {'max_features': 27, 'max_depth': 30}\n",
      "mean train f1 score: 0.9889944576755325     mean validation f1 score: 0.6166715664285315\n",
      "working on params:   {'max_features': 35, 'max_depth': 30}\n",
      "mean train f1 score: 0.9890413473047843     mean validation f1 score: 0.6178028537664553\n",
      "working on params:   {'max_features': 43, 'max_depth': 30}\n",
      "mean train f1 score: 0.9890471646257124     mean validation f1 score: 0.61748638142778\n",
      "working on params:   {'max_features': 51, 'max_depth': 30}\n",
      "mean train f1 score: 0.9890456167012595     mean validation f1 score: 0.6191093025758744\n",
      "working on params:   {'max_features': 27, 'max_depth': 35}\n",
      "mean train f1 score: 0.9889947208867731     mean validation f1 score: 0.6179796113236585\n",
      "working on params:   {'max_features': 35, 'max_depth': 35}\n",
      "mean train f1 score: 0.9890404558771093     mean validation f1 score: 0.6172504766801745\n",
      "working on params:   {'max_features': 43, 'max_depth': 35}\n",
      "mean train f1 score: 0.9890471646257124     mean validation f1 score: 0.616358161307473\n",
      "working on params:   {'max_features': 51, 'max_depth': 35}\n",
      "mean train f1 score: 0.9890456167012595     mean validation f1 score: 0.6211935551733303\n",
      "The best model parameters were: {'max_features': 27, 'max_depth': 25}\n",
      "The corresponding mean validation score is: 0.6213351959609933\n",
      "Test Score:  0.8794813412232836\n",
      "random state: 700 * 8\n",
      "working on params:   {'max_features': 27, 'max_depth': 25}\n",
      "mean train f1 score: 0.9887464562502815     mean validation f1 score: 0.625507252879505\n",
      "working on params:   {'max_features': 35, 'max_depth': 25}\n",
      "mean train f1 score: 0.9887503832499075     mean validation f1 score: 0.6235493604400814\n",
      "working on params:   {'max_features': 43, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886287298283177     mean validation f1 score: 0.6253282069100105\n",
      "working on params:   {'max_features': 51, 'max_depth': 25}\n",
      "mean train f1 score: 0.988750947494798     mean validation f1 score: 0.6176039394313046\n",
      "working on params:   {'max_features': 27, 'max_depth': 30}\n",
      "mean train f1 score: 0.9887484012564689     mean validation f1 score: 0.6255321963048173\n",
      "working on params:   {'max_features': 35, 'max_depth': 30}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train f1 score: 0.9887501533230167     mean validation f1 score: 0.6254192484974966\n",
      "working on params:   {'max_features': 43, 'max_depth': 30}\n",
      "mean train f1 score: 0.9887514476013176     mean validation f1 score: 0.6258392437440687\n",
      "working on params:   {'max_features': 51, 'max_depth': 30}\n",
      "mean train f1 score: 0.9887519639673181     mean validation f1 score: 0.6191408434388492\n",
      "working on params:   {'max_features': 27, 'max_depth': 35}\n",
      "mean train f1 score: 0.9887484012564689     mean validation f1 score: 0.6257326778545091\n",
      "working on params:   {'max_features': 35, 'max_depth': 35}\n",
      "mean train f1 score: 0.9887493662239905     mean validation f1 score: 0.6250345689609921\n",
      "working on params:   {'max_features': 43, 'max_depth': 35}\n",
      "mean train f1 score: 0.9887510944829403     mean validation f1 score: 0.6242989436263486\n",
      "working on params:   {'max_features': 51, 'max_depth': 35}\n",
      "mean train f1 score: 0.9887519639673181     mean validation f1 score: 0.618566236986564\n",
      "The best model parameters were: {'max_features': 43, 'max_depth': 30}\n",
      "The corresponding mean validation score is: 0.6258392437440687\n",
      "Test Score:  0.8695806815814301\n",
      "random state: 700 * 9\n",
      "working on params:   {'max_features': 27, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886472616285537     mean validation f1 score: 0.6133620943630478\n",
      "working on params:   {'max_features': 35, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886495782477183     mean validation f1 score: 0.6164248825956621\n",
      "working on params:   {'max_features': 43, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886527880032633     mean validation f1 score: 0.6128167970281387\n",
      "working on params:   {'max_features': 51, 'max_depth': 25}\n",
      "mean train f1 score: 0.9886457434975047     mean validation f1 score: 0.6178847541156299\n",
      "working on params:   {'max_features': 27, 'max_depth': 30}\n",
      "mean train f1 score: 0.9886534233363072     mean validation f1 score: 0.6145781384007143\n",
      "working on params:   {'max_features': 35, 'max_depth': 30}\n",
      "mean train f1 score: 0.9886510002839665     mean validation f1 score: 0.6177803082436684\n",
      "working on params:   {'max_features': 43, 'max_depth': 30}\n",
      "mean train f1 score: 0.9886527880032633     mean validation f1 score: 0.6163613575492195\n",
      "working on params:   {'max_features': 51, 'max_depth': 30}\n",
      "mean train f1 score: 0.9886502301940204     mean validation f1 score: 0.6179257374533931\n",
      "working on params:   {'max_features': 27, 'max_depth': 35}\n",
      "mean train f1 score: 0.9886534233363072     mean validation f1 score: 0.6140348771081636\n",
      "working on params:   {'max_features': 35, 'max_depth': 35}\n",
      "mean train f1 score: 0.9886517899198287     mean validation f1 score: 0.6191498588014269\n",
      "working on params:   {'max_features': 43, 'max_depth': 35}\n",
      "mean train f1 score: 0.9886532953659608     mean validation f1 score: 0.6155632082211039\n",
      "working on params:   {'max_features': 51, 'max_depth': 35}\n",
      "mean train f1 score: 0.9886502302908773     mean validation f1 score: 0.6184251746156404\n",
      "The best model parameters were: {'max_features': 35, 'max_depth': 35}\n",
      "The corresponding mean validation score is: 0.6191498588014269\n",
      "Test Score:  0.8582149543205584\n"
     ]
    }
   ],
   "source": [
    "param_grid = {  'max_depth': [25, 30, 35], # 5, 7, \n",
    "                'max_features': [27, 35, 43, 51]} # 4, 8, \n",
    "\n",
    "param_grid = ParameterGrid(param_grid)\n",
    "test_scores = np.zeros(10)\n",
    "final_models = []\n",
    "\n",
    "for i in range(10):\n",
    "    random_state = 700 * i \n",
    "    print('random state: 700 * {}'.format(i))\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "            \n",
    "    models = []\n",
    "    train_scores = np.zeros(shape=(4, len(param_grid)))\n",
    "    val_scores = np.zeros(shape=(4, len(param_grid)))\n",
    "    \n",
    "    for p in range(len(param_grid)):\n",
    "        params = param_grid[p]\n",
    "        print('working on params:  ', params) \n",
    "        clf = LabelPowerset(RandomForestClassifier(**params,random_state=random_state))\n",
    "        j = 0\n",
    "        for train_index, val_index in kf.split(X_other):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            X_train_prep = preprocessor.fit_transform(X_train)\n",
    "            X_val_prep = preprocessor.transform(X_val)\n",
    "            X_test_prep = preprocessor.transform(X_test)\n",
    "            clf.fit(X_train_prep, y_train)\n",
    "            \n",
    "            y_train_pred = clf.predict(X_train_prep)\n",
    "            prec = precision_score(y_train, y_train_pred, average=\"macro\", zero_division=0)\n",
    "            rec = recall_score(y_train, y_train_pred, average=\"macro\")\n",
    "            f1 = f1_score(y_train, y_train_pred, average=\"macro\")\n",
    "         #   print('train:', i, \"precision score\", prec, \"recall score\", rec, \"f1 score\", f1)\n",
    "            train_scores[j][p] = f1\n",
    "            \n",
    "            y_val_pred = clf.predict(X_val_prep)\n",
    "            prec_val = precision_score(y_val, y_val_pred, average=\"macro\", zero_division=0)\n",
    "            rec_val = recall_score(y_val, y_val_pred, average=\"macro\")\n",
    "            f1_val = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "          #  print('validation:', i, \"precision score\", prec_val, \"recall score\", rec_val, \"f1 score\", f1_val)\n",
    "            val_scores[j][p] = f1_val\n",
    "            j += 1\n",
    "        models.append(clf) \n",
    "            \n",
    "        print('mean train f1 score:', np.mean(train_scores[:, p]), '    mean validation f1 score:', np.mean(val_scores[:, p]))\n",
    "    amax_mean = np.argmax(np.mean(val_scores, axis=0))\n",
    "    print('The best model parameters were:', param_grid[amax_mean])\n",
    "    print('The corresponding mean validation score is:',np.max(np.mean(val_scores, axis=0)))\n",
    "    final_models.append(models[amax_mean])\n",
    "    y_test_pred = final_models[-1].predict(X_test_prep)\n",
    "    test_scores[i] = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "    print('Test Score: ', test_scores[i])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
