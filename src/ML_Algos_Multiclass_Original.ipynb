{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pylab  as plt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV,  ParameterGrid\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, SelectKBest\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.utils.multiclass import unique_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/features_plus_descriptions.csv')\n",
    "features.set_index('Feature Type and Number', inplace=True)\n",
    "features.drop(['S5', 'D21'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/multiclass_target_raw_data.csv')\n",
    "X = df.loc[:,features.index]\n",
    "y = df['Best Heuristic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax Scaler Features:  ['S1', 'S3', 'S4', 'S6', 'S8', 'S11', 'S12', 'D3', 'D39']\n",
      "Standard Scaler Features:  ['S2', 'S7', 'S9', 'S10', 'S13', 'S14', 'D1', 'D2', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'D16', 'D17', 'D18', 'D19', 'D20', 'D22', 'D23', 'D24', 'D25', 'D26', 'D27', 'D28', 'D29', 'D30', 'D31', 'D32', 'D33', 'D34', 'D35', 'D36', 'D37', 'D38']\n"
     ]
    }
   ],
   "source": [
    "types = dict.fromkeys(features.index, 'stdsc')\n",
    "mm_feats = ['S1','S3', 'S4', 'S6', 'S8','S11', 'S12', 'D3', 'D39']\n",
    "\n",
    "for feat in mm_feats:\n",
    "    types[feat] = 'minmax'\n",
    "\n",
    "minmax_feats = []\n",
    "std_feats = []\n",
    "\n",
    "for feat in types.keys():\n",
    "    if types[feat] == 'stdsc':\n",
    "        std_feats.append(feat)\n",
    "    elif types[feat] == 'minmax':\n",
    "        minmax_feats.append(feat)\n",
    "\n",
    "print('MinMax Scaler Features: ', minmax_feats)\n",
    "print('Standard Scaler Features: ', std_feats)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('mm_scaler', MinMaxScaler(), minmax_feats),\n",
    "        ('std_scaler', StandardScaler(), std_feats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "    plt.rcParams['figure.dpi'] = 300\n",
    "    plt.rcParams['figure.figsize'] = (8,8)\n",
    "    plt.rcParams['font.size'] = 8\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "  #  classes = np.array(classes)\n",
    "  #  classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(10,10))    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline_KFold_orig(X, y, preprocessor, ML_algo, param_grid):\n",
    "    \"\"\"\n",
    "    This function splits the data into other and test sets (80-20 split) and\n",
    "    then applies KFold with 4 folds to other set. \n",
    "    \"\"\"\n",
    "    test_scores = []\n",
    "    best_models = []\n",
    "    ys = []\n",
    "    for i in range(1, 6):\n",
    "        random_state = 431*i\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "        clf = Pipeline([\n",
    "        ('preprocessor', preprocessor), \n",
    "        ('clf', ML_algo)\n",
    "        ])\n",
    "        grid = GridSearchCV(clf, param_grid, scoring='f1_macro',cv=kf,  return_train_score=True, verbose=4, n_jobs=-1)  \n",
    "        grid.fit(X_other, y_other)\n",
    "        y_pred = grid.predict(X_test)\n",
    "        prec = precision_score(y_test, y_pred, average=\"macro\")\n",
    "        rec = recall_score(y_test, y_pred, average=\"macro\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        best_models.append(grid.best_params_)\n",
    "        print(\"best params\", grid.best_params_, \"precision score\", prec, \"recall score\", rec, \"f1 score\", f1)\n",
    "        test_scores.append((prec, rec, f1))\n",
    "        ys.append((y_test, y_pred, [0,1,2,3,4,5]))\n",
    "    return test_scores, best_models, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params {'clf__random_state': 1293} precision score 0.1548702636583802 recall score 0.16324590340469733 f1 score 0.1459648037024512\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params {'clf__random_state': 1724} precision score 0.16238449353011247 recall score 0.1649415441764084 f1 score 0.14608595351644268\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params {'clf__random_state': 1293} precision score 0.15533817269893752 recall score 0.15888335508849546 f1 score 0.1423048644170937\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params {'clf__random_state': 431} precision score 0.15733727865373254 recall score 0.1598297804797557 f1 score 0.14390476436659697\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params {'clf__random_state': 2155} precision score 0.17386842729916308 recall score 0.16719028036074576 f1 score 0.1559323891856043\n",
      "{'clf__random_state': 1293}\n",
      "{'clf__random_state': 1724}\n",
      "{'clf__random_state': 1293}\n",
      "{'clf__random_state': 431}\n",
      "{'clf__random_state': 2155}\n"
     ]
    }
   ],
   "source": [
    "ML_algo = DummyClassifier(strategy=\"uniform\")\n",
    "param_grid = { 'clf__random_state': [431, 431*2, 431*3, 431*4, 431*5]}\n",
    "\n",
    "scores_dummy, models_dummy, ys_dummy = ML_pipeline_KFold_orig(X, y, preprocessor, ML_algo, param_grid)\n",
    "\n",
    "for m in models_dummy:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { 'clf__max_depth': [15, 20, 25, 30], \n",
    "               'clf__max_features':[10, 15, 20, 25, 30] }\n",
    "\n",
    "ML_algo = RandomForestClassifier()\n",
    "pg = ParameterGrid(param_grid)\n",
    "scores_orig_RF, models_orig_RF, ys_orig_RF = ML_pipeline_KFold_orig(X, y, preprocessor, ML_algo, param_grid)\n",
    "\n",
    "for p, r, f in scores_orig_RF:\n",
    "    print(\"precision: {}      , recall: {}, f1: {}\".format(p,r, f))\n",
    "    \n",
    "for m in models_orig_RF: \n",
    "    print(m)\n",
    "\n",
    "print(type(ys_orig_RF[0][0]))\n",
    "yt, yp, classes = ys_orig_RF[0][0], ys_orig_RF[1][0], ys_orig_RF[2]\n",
    "cl = [[0], [1], [2], [3], [4], [5]]\n",
    "plot_confusion_matrix(yt, yp, cl, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
