{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for S in range(6):\n",
    "    print(\"SUM = \", S)\n",
    "    for a in range(len(counts_strict)):\n",
    "        if np.sum(unique_rows_strict[a]) == S:\n",
    "            print(unique_rows_strict[a], counts_strict[a]) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic_positives = {i:0 for i in range(6)}\n",
    "\n",
    "for s in range(len(unique_rows_strict[a])):\n",
    "    print(\"heuristic 1 positive\", s)\n",
    "    for a in range(len(counts_strict)):\n",
    "        if unique_rows_strict[a][s] == 1:\n",
    "            print(unique_rows_strict[a], counts_strict[a])\n",
    "            heuristic_positives[s] += counts_strict[a]\n",
    "heuristic_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacks = {}\n",
    "stacks[0] = [(1,2,3,4), (1,2,3), (1,3,4), (1,2,4), (2,3,4), (1,2), (1,3), (1,4), (2,3), (2,4), (3,4)]\n",
    "stacks[1] = [(2,3,4,5), (2,3,4), (3,4,5), (2,4,5), (2,3,5), (2,3), (2,4), (2,5), (3,4), (3,5), (4,5)]\n",
    "stacks[2] = [(1,2,3,5), (1,2,5), (1,2,3), (1,3,5), (2,3,5), (1,2), (1,3), (1,5), (2,3), (2,5), (3,5)]\n",
    "stacks[3] = [(1,2,4,5), (1,2,4), (1,2,5), (1,4,5), (2,4,5), (1,2), (1,4), (1,5), (2,4), (2,5), (4,5)]\n",
    "stacks[4] = [(1,3,4,5), (1,3,4), (1,3,5), (1,4,5), (3,4,5), (1,3), (1,4), (1,5), (3,4), (3,5), (4,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    singlets = [0, 1, 2, 3, 4, 5]\n",
    "    pairs = [(1,2), (2,3), (3,4), (4,5), (1,3), (1,4), (1,5), (2,4), (2,5), (3,5)]\n",
    "    triplets = [(1,2,3), (1,3,4), (2,3,4), (3,4,5), (1,2,4), (1,2,5), (1,3,5), (1,4,5), (2,4,5), (2,3,5)]\n",
    "    quads = [(1,2,3,4), (1,2,3,5), (2,3,4,5), (1,2,4,5), (1,3,4,5)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " #  OVR = OneVsRestClassifier(SVC)\n",
    "        clf = make_pipeline(preprocessor, svc)\n",
    "        for train_index, val_index in kf.split(X_other, y_other):\n",
    "            X_train = X_other.iloc[train_index]\n",
    "            X_val = X_other.iloc[val_index]\n",
    "            y_train = y_other.iloc[train_index]\n",
    "            y_val = y_other.iloc[val_index]\n",
    "            X_train_prep = clf.fit_transform(X_train)\n",
    "            X_val_prep = clf.transform(X_val)\n",
    "            train_score = f1_score(y_train, clf.predict(X_train_prep), average=\"macro\")\n",
    "            val_score = f1_score(y_val, clf.predict(X_val_prep), average=\"macro\") \n",
    "            print(\"val score\", val_score)\n",
    "        X_test_prep = clf.transform(X_test)\n",
    "        y_pred = clf.predict(X_test_prep)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        print(params, \"test score\", f1)\n",
    "        test_scores.append(f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_algo = \n",
    "\n",
    "models, scores = ML_pipeline_KFold_log_loss(X, y, preprocessor, ML_algo, param_grid)\n",
    "\n",
    "print('SVC Log Loss:', scores)\n",
    "\n",
    "print('mean and std:', np.mean(scores), np.std(scores))\n",
    "\n",
    "for m in models:\n",
    "    print(m)\n",
    "\n",
    "\n",
    "    test_scores = []\n",
    "best_models = []\n",
    "n_neighbors = [1,2,3,4,5,6,7,8,9,10]# 15, 20, 30, 50, 75]\n",
    "\n",
    "param_grid = {'n_neighbors': n_neighbors, 'weights': ['distance', 'uniform']}\n",
    "pg = ParameterGrid(param_grid)\n",
    "for j in range(len(pg)):\n",
    "    params = pg[j]\n",
    "    for i in range(1,2):\n",
    "        random_state = 431 * i\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "        KNN = KNeighborsClassifier(**params)\n",
    "       # KNN.set_params()\n",
    "        OVR = OneVsRestClassifier(KNN)\n",
    "        clf = make_pipeline(preprocessor, OVR)\n",
    "        for train_index, val_index in kf.split(X_other, y_other):\n",
    "            X_train = X_other.iloc[train_index]\n",
    "            X_val = X_other.iloc[val_index]\n",
    "            y_train = y_other.iloc[train_index]\n",
    "            y_val = y_other.iloc[val_index]\n",
    "            X_train_prep = clf.fit_transform(X_train)\n",
    "            X_val_prep = clf.transform(X_val)\n",
    "            train_score = f1_score(y_train, clf.predict(X_train_prep), average=\"macro\")\n",
    "            val_score = f1_score(y_val, clf.predict(X_val_prep), average=\"macro\") \n",
    "            print(\"val score\", val_score)\n",
    "        X_test_prep = clf.transform(X_test)\n",
    "        y_pred = clf.predict(X_test_prep)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        print(params, \"test score\", f1)\n",
    "        test_scores.append(f1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline_KFold_f1_macro(X, y, preprocessor, ML_algo, param_grid):\n",
    "    \"\"\"\n",
    "    This function splits the data into other and test sets (80-20 split) and\n",
    "    then applies KFold with 4 folds to other set.\n",
    "    \n",
    "    f1 score \n",
    "    \"\"\"\n",
    "    test_scores = []\n",
    "    best_models = []\n",
    "    for i in range(1,11):\n",
    "        random_state = 431 * i\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "        clf = make_pipeline(preprocessor, OneVsRestClassifier(ML_algo))\n",
    "        grid = GridSearchCV(clf, param_grid=param_grid, scoring='f1_macro', cv=kf, return_train_score=True)   \n",
    "        grid.fit(X_other, y_other)\n",
    "        best_models.append(grid.best_params_)\n",
    "        y_pred = grid.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        print(\"best params\", grid.best_params_, \"score\", f1)\n",
    "        test_scores.append(f1)\n",
    "    return best_models, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline_KFold_f1_micro(X, y, preprocessor, ML_algo, param_grid):\n",
    "    \"\"\"\n",
    "    This function splits the data into other and test sets (80-20 split) and\n",
    "    then applies KFold with 4 folds to other set. The log-loss is minimized \n",
    "    in cross validation.\n",
    "    \"\"\"\n",
    "    test_scores = []\n",
    "    best_models = []\n",
    "    for i in range(1,3):\n",
    "        random_state = 431 * i\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "        clf = make_pipeline(preprocessor, OneVsRestClassifier(ML_algo))\n",
    "        grid = GridSearchCV(clf, param_grid=param_grid, scoring='f1_micro', cv=kf, return_train_score=True)   \n",
    "        grid.fit(X_other, y_other)\n",
    "        best_models.append(grid.best_params_)\n",
    "        y_pred = grid.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "        print(\"best params\", grid.best_params_, \"score\", f1)\n",
    "        test_scores.append(f1)\n",
    "    return best_models, test_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_neighbors = [5,10,15,20,30,40,50,60,70,75]#, 100, 125, 150, 175, 200] # 3, 5, 10, 15, 20, 25, 30, 40, 175, 200, 250, 300\n",
    "n_neighbors = [5,10,15,20,25]\n",
    "ML_algo = KNeighborsClassifier()\n",
    "ML_algo = \n",
    "param_grid = {'kneighborsclassifier__n_neighbors': n_neighbors, 'kneighborsclassifier__weights': ['distance', 'uniform']}\n",
    "\n",
    "models, scores = ML_pipeline_KFold_f1_weighted(X, y, preprocessor, ML_algo, param_grid)\n",
    "print('KNN f1:', scores, np.mean(scores), np.std(scores))\n",
    "print('Best Models:')\n",
    "for m in models:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "best_models = []\n",
    "n_neighbors = [1,2,3,4,5,6,7,8,9,10]# 15, 20, 30, 50, 75]\n",
    "\n",
    "param_grid = {'n_neighbors': n_neighbors, 'weights': ['distance', 'uniform']}\n",
    "pg = ParameterGrid(param_grid)\n",
    "for j in range(len(pg)):\n",
    "    params = pg[j]\n",
    "    for i in range(1,2):\n",
    "        random_state = 431 * i\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "        KNN = KNeighborsClassifier(**params)\n",
    "       # KNN.set_params()\n",
    "        OVR = OneVsRestClassifier(KNN)\n",
    "        clf = make_pipeline(preprocessor, OVR)\n",
    "        for train_index, val_index in kf.split(X_other, y_other):\n",
    "            X_train = X_other.iloc[train_index]\n",
    "            X_val = X_other.iloc[val_index]\n",
    "            y_train = y_other.iloc[train_index]\n",
    "            y_val = y_other.iloc[val_index]\n",
    "            X_train_prep = clf.fit_transform(X_train)\n",
    "            X_val_prep = clf.transform(X_val)\n",
    "            train_score = f1_score(y_train, clf.predict(X_train_prep), average=\"macro\")\n",
    "            val_score = f1_score(y_val, clf.predict(X_val_prep), average=\"macro\") \n",
    "            print(\"val score\", val_score)\n",
    "        X_test_prep = clf.transform(X_test)\n",
    "        y_pred = clf.predict(X_test_prep)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        print(params, \"test score\", f1)\n",
    "        test_scores.append(f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "best_models = []\n",
    "for i in range(1,3):\n",
    "    random_state = 431 * i\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "    clf = make_pipeline(preprocessor, ML_algo)\n",
    "    grid = GridSearchCV(clf, param_grid=param_grid,\n",
    "                            scoring='f1_micro', cv=kf, return_train_score=True)   \n",
    "    grid.fit(X_other, y_other)\n",
    "    best_models.append(grid.best_params_)\n",
    "    y_pred = grid.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    print(\"best params\", grid.best_params_, \"score\", acc_score)\n",
    "    test_scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "best_models = []\n",
    "n_neighbors = [1,2,3,4,5,6,7,8,9,10]# 15, 20, 30, 50, 75]\n",
    "\n",
    "for n in n_neighbors:\n",
    "    for i in range(1,3):\n",
    "        random_state = 431 * i\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "        clf = make_pipeline(preprocessor, OneVsRestClassifier(KNeighborsClassifier(n_neighbors=n)))\n",
    "        for train_index, val_index in kf.split(X_other, y_other):\n",
    "            X_train = X_other.iloc[train_index]\n",
    "            X_val = X_other.iloc[val_index]\n",
    "            y_train = y_other.iloc[train_index]\n",
    "            y_val = y_other.iloc[val_index]\n",
    "            X_train_prep = clf.fit(X_train)\n",
    "            X_val_prep = clf.transform(X_val)\n",
    "            val_score = f1_score(y_val, clf.predict(X_val_prep)) \n",
    "            print(\"val score\", val_score)\n",
    "        X_test_prep = clf.transform(X_test)\n",
    "        y_pred = clf.predict(X_test_prep)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "        print(n, \"test score\", f1)\n",
    "        test_scores.append(f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
