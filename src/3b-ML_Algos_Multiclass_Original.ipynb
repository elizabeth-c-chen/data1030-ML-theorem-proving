{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3b: Machine Learning - Original Multi-class (Single Label) Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/features_plus_descriptions.csv')\n",
    "features.set_index('Feature Type and Number', inplace=True)\n",
    "features.drop(['S5', 'D21'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/multiclass_raw_data.csv')\n",
    "X = df.loc[:,features.index]\n",
    "y = df['Best Heuristic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(X, y, ML_algo, param_grid):\n",
    "    \"\"\"\n",
    "    This function splits the data into other and test sets (80-20 split) and\n",
    "    then applies KFold with 4 folds to other set and runs GridSearchCV to find\n",
    "    the best estimator. It returns the test scores and models generated by each\n",
    "    random state.\n",
    "    \"\"\"\n",
    "    test_scores = []\n",
    "    best_models = []\n",
    "    for i in range(10):\n",
    "        random_state = 431 * i\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "        pipe = Pipeline([\n",
    "            (\"preprocessor\", StandardScaler()), \n",
    "            (\"clf\", ML_algo)\n",
    "        ])\n",
    "        grid = GridSearchCV(pipe, param_grid, scoring=\"f1_micro\", cv=kf, return_train_score=True, verbose=5, n_jobs=-1)   \n",
    "        grid.fit(X_other, y_other)\n",
    "        y_pred = grid.predict(X_test)\n",
    "        prec = precision_score(y_test, y_pred, average=\"micro\")\n",
    "        rec = recall_score(y_test, y_pred, average=\"micro\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "        print(\"Best Params: {} \\nBest CV Score: {}\".format(grid.best_params_, np.round(grid.best_score_, decimals=6)))\n",
    "        print(\"Precision:     {}\\nRecall:        {}\\nf1_micro:      {} \\n\".format(np.round(prec, decimals=6), np.round(rec, decimals=6),np.round(f1, decimals=6)))\n",
    "        test_scores.append(f1)\n",
    "        best_models.append(grid)\n",
    "    return test_scores, best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Best Params: {'clf__strategy': 'most_frequent'} \n",
      "Best CV Score: 0.411319\n",
      "Precision:     0.441993\n",
      "Recall:        0.441993\n",
      "f1_micro:      0.441993 \n",
      "\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Best Params: {'clf__strategy': 'most_frequent'} \n",
      "Best CV Score: 0.424806\n",
      "Precision:     0.388072\n",
      "Recall:        0.388072\n",
      "f1_micro:      0.388072 \n",
      "\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Best Params: {'clf__strategy': 'most_frequent'} \n",
      "Best CV Score: 0.41479\n",
      "Precision:     0.428105\n",
      "Recall:        0.428105\n",
      "f1_micro:      0.428105 \n",
      "\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Best Params: {'clf__strategy': 'most_frequent'} \n",
      "Best CV Score: 0.414179\n",
      "Precision:     0.430556\n",
      "Recall:        0.430556\n",
      "f1_micro:      0.430556 \n",
      "\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Best Params: {'clf__strategy': 'most_frequent'} \n",
      "Best CV Score: 0.413978\n",
      "Precision:     0.431373\n",
      "Recall:        0.431373\n",
      "f1_micro:      0.431373 \n",
      "\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Best Params: {'clf__strategy': 'most_frequent'} \n",
      "Best CV Score: 0.418063\n",
      "Precision:     0.415033\n",
      "Recall:        0.415033\n",
      "f1_micro:      0.415033 \n",
      "\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Best Params: {'clf__strategy': 'most_frequent'} \n",
      "Best CV Score: 0.413364\n",
      "Precision:     0.433824\n",
      "Recall:        0.433824\n",
      "f1_micro:      0.433824 \n",
      "\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Best Params: {'clf__strategy': 'most_frequent'} \n",
      "Best CV Score: 0.422147\n",
      "Precision:     0.398693\n",
      "Recall:        0.398693\n",
      "f1_micro:      0.398693 \n",
      "\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Best Params: {'clf__strategy': 'most_frequent'} \n",
      "Best CV Score: 0.418264\n",
      "Precision:     0.414216\n",
      "Recall:        0.414216\n",
      "f1_micro:      0.414216 \n",
      "\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Best Params: {'clf__strategy': 'most_frequent'} \n",
      "Best CV Score: 0.419079\n",
      "Precision:     0.410948\n",
      "Recall:        0.410948\n",
      "f1_micro:      0.410948 \n",
      "\n",
      "best random state index: 0\n",
      "max test score for Dummy Classifier: 0.44199346405228757\n",
      "best params for Dummy Classifier: {'clf__strategy': 'most_frequent'}\n",
      "mean test score for Dummy Classifier: 0.419281045751634\n",
      "stdev of test score for Dummy Classifier: 0.016092075352334156\n"
     ]
    }
   ],
   "source": [
    "ML_algo = DummyClassifier()\n",
    "param_grid = { 'clf__strategy':  [\"stratified\", \"most_frequent\", \"prior\", \"uniform\"] }\n",
    "\n",
    "test_scores_dummy, best_models_dummy = run_pipeline(X, y, ML_algo, param_grid)\n",
    "\n",
    "amax = np.argmax(test_scores_dummy)\n",
    "print('best random state index:', amax)\n",
    "print('max test score for Dummy Classifier:', test_scores_dummy[amax])\n",
    "print('best params for Dummy Classifier:', best_models_dummy[amax].best_params_)\n",
    "\n",
    "print('mean test score for Dummy Classifier:', np.mean(test_scores_dummy) )\n",
    "print('stdev of test score for Dummy Classifier:', np.std(test_scores_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n",
      "Best Params: {'clf__max_depth': 15, 'clf__max_features': 15} \n",
      "Best CV Score: 0.61177\n",
      "Precision:     0.633987\n",
      "Recall:        0.633987\n",
      "f1_micro:      0.633987 \n",
      "\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n",
      "Best Params: {'clf__max_depth': 15, 'clf__max_features': 20} \n",
      "Best CV Score: 0.608501\n",
      "Precision:     0.627451\n",
      "Recall:        0.627451\n",
      "f1_micro:      0.627451 \n",
      "\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n",
      "Best Params: {'clf__max_depth': 30, 'clf__max_features': 35} \n",
      "Best CV Score: 0.613609\n",
      "Precision:     0.638889\n",
      "Recall:        0.638889\n",
      "f1_micro:      0.638889 \n",
      "\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n",
      "Best Params: {'clf__max_depth': 20, 'clf__max_features': 25} \n",
      "Best CV Score: 0.611358\n",
      "Precision:     0.621732\n",
      "Recall:        0.621732\n",
      "f1_micro:      0.621732 \n",
      "\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n",
      "Best Params: {'clf__max_depth': 25, 'clf__max_features': 45} \n",
      "Best CV Score: 0.612178\n",
      "Precision:     0.611928\n",
      "Recall:        0.611928\n",
      "f1_micro:      0.611928 \n",
      "\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n",
      "Best Params: {'clf__max_depth': 25, 'clf__max_features': 30} \n",
      "Best CV Score: 0.608092\n",
      "Precision:     0.619281\n",
      "Recall:        0.619281\n",
      "f1_micro:      0.619281 \n",
      "\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n",
      "Best Params: {'clf__max_depth': 35, 'clf__max_features': 25} \n",
      "Best CV Score: 0.607888\n",
      "Precision:     0.647876\n",
      "Recall:        0.647876\n",
      "f1_micro:      0.647876 \n",
      "\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n",
      "Best Params: {'clf__max_depth': 20, 'clf__max_features': 20} \n",
      "Best CV Score: 0.612382\n",
      "Precision:     0.611111\n",
      "Recall:        0.611111\n",
      "f1_micro:      0.611111 \n",
      "\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n",
      "Best Params: {'clf__max_depth': 35, 'clf__max_features': 45} \n",
      "Best CV Score: 0.605638\n",
      "Precision:     0.625817\n",
      "Recall:        0.625817\n",
      "f1_micro:      0.625817 \n",
      "\n",
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n",
      "Best Params: {'clf__max_depth': 15, 'clf__max_features': 25} \n",
      "Best CV Score: 0.607268\n",
      "Precision:     0.622549\n",
      "Recall:        0.622549\n",
      "f1_micro:      0.622549 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML_algo = RandomForestClassifier()\n",
    "param_grid = { 'clf__max_depth': [15, 20, 25, 30, 35, 40], \n",
    "               'clf__max_features':[15, 20, 25, 30, 35, 40, 45, 51] }\n",
    "\n",
    "test_scores_RF, best_models_RF = run_pipeline(X, y, ML_algo, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best random state index: 6\n",
      "max test score for Random Forest: 0.6478758169934641\n",
      "best params for Random Forest: {'clf__max_depth': 35, 'clf__max_features': 25}\n"
     ]
    }
   ],
   "source": [
    "amax = np.argmax(test_scores_RF)\n",
    "print('best random state index:', amax)\n",
    "print('max test score for Random Forest:', test_scores_RF[amax])\n",
    "print('best params for Random Forest:', best_models_RF[amax].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test score for Random Forest: 0.626062091503268\n",
      "stdev of test score for Random Forest: 0.01097967483262293\n"
     ]
    }
   ],
   "source": [
    "print('mean test score for Random Forest:', np.mean(test_scores_RF) )\n",
    "print('stdev of test score for Random Forest:', np.std(test_scores_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Best Params: {'clf__n_neighbors': 30, 'clf__weights': 'distance'} \n",
      "Best CV Score: 0.576216\n",
      "Precision:     0.594771\n",
      "Recall:        0.594771\n",
      "f1_micro:      0.594771 \n",
      "\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Best Params: {'clf__n_neighbors': 10, 'clf__weights': 'distance'} \n",
      "Best CV Score: 0.579077\n",
      "Precision:     0.589052\n",
      "Recall:        0.589052\n",
      "f1_micro:      0.589052 \n",
      "\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Best Params: {'clf__n_neighbors': 20, 'clf__weights': 'distance'} \n",
      "Best CV Score: 0.578871\n",
      "Precision:     0.595588\n",
      "Recall:        0.595588\n",
      "f1_micro:      0.595588 \n",
      "\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Best Params: {'clf__n_neighbors': 20, 'clf__weights': 'distance'} \n",
      "Best CV Score: 0.583161\n",
      "Precision:     0.588235\n",
      "Recall:        0.588235\n",
      "f1_micro:      0.588235 \n",
      "\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Best Params: {'clf__n_neighbors': 10, 'clf__weights': 'distance'} \n",
      "Best CV Score: 0.574582\n",
      "Precision:     0.607843\n",
      "Recall:        0.607843\n",
      "f1_micro:      0.607843 \n",
      "\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Best Params: {'clf__n_neighbors': 15, 'clf__weights': 'distance'} \n",
      "Best CV Score: 0.576013\n",
      "Precision:     0.602124\n",
      "Recall:        0.602124\n",
      "f1_micro:      0.602124 \n",
      "\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Best Params: {'clf__n_neighbors': 5, 'clf__weights': 'distance'} \n",
      "Best CV Score: 0.575607\n",
      "Precision:     0.617647\n",
      "Recall:        0.617647\n",
      "f1_micro:      0.617647 \n",
      "\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Best Params: {'clf__n_neighbors': 10, 'clf__weights': 'distance'} \n",
      "Best CV Score: 0.57826\n",
      "Precision:     0.593137\n",
      "Recall:        0.593137\n",
      "f1_micro:      0.593137 \n",
      "\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Best Params: {'clf__n_neighbors': 20, 'clf__weights': 'distance'} \n",
      "Best CV Score: 0.576418\n",
      "Precision:     0.601307\n",
      "Recall:        0.601307\n",
      "f1_micro:      0.601307 \n",
      "\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Best Params: {'clf__n_neighbors': 15, 'clf__weights': 'distance'} \n",
      "Best CV Score: 0.573148\n",
      "Precision:     0.583333\n",
      "Recall:        0.583333\n",
      "f1_micro:      0.583333 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML_algo = KNeighborsClassifier()\n",
    "param_grid ={ 'clf__n_neighbors': [5,10,15,20,30,40,50,60],\n",
    "              'clf__weights': ['distance', 'uniform'] }\n",
    "best_scores_KNN, best_models_KNN = run_pipeline(X, y, ML_algo, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best random state index: 6\n",
      "max test score for K Nearest Neighbors: 0.6176470588235294\n",
      "best params for K Nearest Neighbors: {'clf__n_neighbors': 5, 'clf__weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "amax = np.argmax(best_scores_KNN)\n",
    "print('best random state index:', amax)\n",
    "print('max test score for K Nearest Neighbors:', best_scores_KNN[amax])\n",
    "print('best params for K Nearest Neighbors:', best_models_KNN[amax].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test score for K Nearest Neighbors: 0.5973039215686273\n",
      "stdev of test score for K Nearest Neighbors: 0.009676803891547556\n"
     ]
    }
   ],
   "source": [
    "print('mean test score for K Nearest Neighbors:', np.mean(best_scores_KNN) )\n",
    "print('stdev of test score for K Nearest Neighbors:', np.std(best_scores_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_algo = OneVsRestClassifier(SVC(max_iter=100000000, cache_size=3000))\n",
    "\n",
    "param_grid = { 'clf__estimator__C': np.logspace(1,4,num=4),\n",
    "               'clf__estimator__tol': np.logspace(-4, -2,num=3) } \n",
    "\n",
    "test_scores_SVC, best_models_SVC = run_pipeline(X, y, ML_algo, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amax = np.argmax(test_scores_SVC)\n",
    "print(amax)\n",
    "print('best test score for SVC OneVsRest:', test_scores_SVC[amax])\n",
    "print('best estimator for SVC OneVsRest:', best_models_SVC[amax].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean test score for SVC OneVsRest:', np.mean(test_scores_SVC) )\n",
    "print('stdev of test score for SVC OneVsRest:', np.std(test_scores_SVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_algo = OneVsRestClassifier(LogisticRegression(max_iter=100000, warm_start=True, multi_class='ovr'))\n",
    "param_grid = { 'clf__estimator__penalty': ['l2'],\n",
    "               'clf__estimator__C': np.logspace(0, 4, 5),\n",
    "               'clf__estimator__solver': ['sag', 'lbfgs'] }\n",
    "\n",
    "test_scores_LR, best_models_LR = run_pipeline(X, y, ML_algo, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amax = np.argmax(test_scores_LR)\n",
    "print('best random state index:', amax)\n",
    "print('max test score for Log Reg:', test_scores_LR[amax])\n",
    "print('best params for Log Reg:', best_models_LR[amax].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean test score for Log Reg:', np.mean(test_scores_LR) )\n",
    "print('stdev of test score for Log Reg:', np.std(test_scores_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
