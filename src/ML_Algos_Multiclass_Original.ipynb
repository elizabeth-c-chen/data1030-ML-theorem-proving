{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/features_plus_descriptions.csv')\n",
    "features.set_index('Feature Type and Number', inplace=True)\n",
    "features.drop(['S5', 'D21'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/multiclass_raw_data.csv')\n",
    "X = df.loc[:,features.index]\n",
    "y = df['Best Heuristic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(X, y, ML_algo, param_grid):\n",
    "    \"\"\"\n",
    "    This function splits the data into other and test sets (80-20 split) and\n",
    "    then applies KFold with 4 folds to other set and runs GridSearchCV to find\n",
    "    the best estimator. It returns the test scores and models generated by each\n",
    "    random state.\n",
    "    \"\"\"\n",
    "    test_scores = []\n",
    "    best_models = []\n",
    "    for i in range(10):\n",
    "        random_state = 431 * i\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\n",
    "        kf = StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "        pipe = Pipeline([\n",
    "            (\"preprocessor\", StandardScaler()), \n",
    "            (\"clf\", ML_algo)\n",
    "        ])\n",
    "        grid = GridSearchCV(pipe, param_grid, scoring=\"f1_micro\", cv=kf, return_train_score=True, verbose=5, n_jobs=-1)   \n",
    "        grid.fit(X_other, y_other)\n",
    "        y_pred = grid.predict(X_test)\n",
    "        prec = precision_score(y_test, y_pred, average=\"micro\")\n",
    "        rec = recall_score(y_test, y_pred, average=\"micro\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "        print(\"Best Params: {} \\nBest CV Score: {}\".format(grid.best_params_, np.round(grid.best_score_, decimals=6)))\n",
    "        print(\"Precision:     {}\\nRecall:        {}\\nf1_micro:      {} \\n\".format(np.round(prec, decimals=6), np.round(rec, decimals=6),np.round(f1, decimals=6)))\n",
    "        test_scores.append(f1)\n",
    "        best_models.append(grid)\n",
    "    return test_scores, best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ML_algo = DummyClassifier()\n",
    "param_grid = { 'clf__strategy':  [\"stratified\", \"most_frequent\", \"prior\", \"uniform\"] }\n",
    "\n",
    "test_scores_dummy, best_models_dummy = run_pipeline(X, y, ML_algo, param_grid)\n",
    "\n",
    "amax = np.argmax(test_scores_dummy)\n",
    "print('best random state index:', amax)\n",
    "print('max test score for Dummy Classifier:', test_scores_dummy[amax])\n",
    "print('best params for Dummy Classifier:', best_models_dummy[amax].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ML_algo = RandomForestClassifier()\n",
    "param_grid = { 'clf__max_depth': [15, 20, 25, 30, 35, 40], \n",
    "               'clf__max_features':[15, 20, 25, 30, 35, 40, 45, 51] }\n",
    "\n",
    "test_scores_RF, best_models_RF = run_pipeline(X, y, ML_algo, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amax = np.argmax(test_scores_RF)\n",
    "print('best random state index:', amax)\n",
    "print('max test score for Random Forest:', test_scores_RF[amax])\n",
    "print('best params for Random Forest:', best_models_RF[amax].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean test score for Random Forest:', np.mean(test_scores_RF) )\n",
    "print('stdev of test score for Random Forest:', np.std(test_scores_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_algo = KNeighborsClassifier()\n",
    "param_grid ={ 'clf__n_neighbors': [5,10,15,20,30,40,50,60],\n",
    "              'clf__weights': ['distance', 'uniform'] }\n",
    "best_scores_KNN, best_models_KNN = run_pipeline(X, y, ML_algo, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amax = np.argmax(best_scores_KNN)\n",
    "print('best random state index:', amax)\n",
    "print('max test score for K Nearest Neighbors:', best_scores_KNN[amax])\n",
    "print('best params for K Nearest Neighbors:', best_models_KNN[amax].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean test score for K Nearest Neighbors:', np.mean(best_scores_KNN) )\n",
    "print('stdev of test score for K Nearest Neighbors:', np.std(best_scores_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_algo = OneVsRestClassifier(SVC(max_iter=100000000, cache_size=3000))\n",
    "\n",
    "param_grid = { 'clf__estimator__C': np.logspace(1,4,num=4),\n",
    "               'clf__estimator__tol': np.logspace(-4, -2,num=3) } \n",
    "\n",
    "test_scores_SVC, best_models_SVC = run_pipeline(X, y, ML_algo, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amax = np.argmax(test_scores_SVC)\n",
    "print(amax)\n",
    "print('best test score for SVC OneVsRest:', test_scores_SVC[amax])\n",
    "print('best estimator for SVC OneVsRest:', best_models_SVC[amax].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean test score for SVC OneVsRest:', np.mean(test_scores_SVC) )\n",
    "print('stdev of test score for SVC OneVsRest:', np.std(test_scores_SVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_algo = OneVsRestClassifier(LogisticRegression(max_iter=100000, warm_start=True, multi_class='ovr'))\n",
    "param_grid = { 'clf__estimator__penalty': ['l2'],\n",
    "               'clf__estimator__C': np.logspace(0, 4, 5),\n",
    "               'clf__estimator__solver': ['sag', 'lbfgs'] }\n",
    "\n",
    "test_scores_LR, best_models_LR = run_pipeline(X, y, ML_algo, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amax = np.argmax(test_scores_LR)\n",
    "print('best random state index:', amax)\n",
    "print('max test score for Log Reg:', test_scores_LR[amax])\n",
    "print('best params for Log Reg:', best_models_LR[amax].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean test score for Log Reg:', np.mean(test_scores_LR) )\n",
    "print('stdev of test score for Log Reg:', np.std(test_scores_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
